{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stitch2D Mosaic Fn. Ported to Python-3 Notebook format\n",
    "# Based on: https://github.com/adamancer/stitch2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"A Python script used to stitch a two-dimensional tileset into a mosaic.\n",
    "It includes functions to test and sort the tilset and to determine the\n",
    "placement of tiles within the final mosaic. Install with\n",
    ":code:`pip install stitch2d`.\n",
    "\n",
    "The easiest way to stitch a tileset is to use the\n",
    ":py:func:`~Stitch2D.Mosaic.mosey` function, which is accessible\n",
    "from the command line: :code:`stitch2d mosaic`. Use the -h flag to\n",
    "see additional options.\n",
    "\"\"\"\n",
    "\n",
    "import csv\n",
    "import glob\n",
    "import os\n",
    "import shlex\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "import tkinter\n",
    "from tkinter import filedialog\n",
    "import json as serialize\n",
    "from copy import copy\n",
    "from datetime import datetime\n",
    "from textwrap import fill\n",
    "\n",
    "try:\n",
    "    import cv2\n",
    "except ImportError:\n",
    "    pass\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFilter, ImageFont\n",
    "\n",
    "IMAGE_MAP = {\n",
    "    '.jpg' : 'JPEG',\n",
    "    '.tif' : 'TIFF',\n",
    "    '.tiff' : 'TIFF'\n",
    "}\n",
    "\n",
    "IMAGE_TYPES = {\n",
    "    'unspecified' : 'unspecified image type',\n",
    "    'ref' : 'petrographic microscope, reflected light',\n",
    "    'rfl' : 'petrographic microscope, reflected light',\n",
    "    'rl' : 'petrographic microscope, reflected light',\n",
    "    'ppl' : 'petrographic microscope, transmitted light',\n",
    "    'trans' : 'petrographic microscope, transmitted light',\n",
    "    'xpl' : 'petrographic microscope, cross-polarized light',\n",
    "    'xpol' : 'petrographic microscope, cross-polarized light',\n",
    "    'bse' : 'SEM, backscatter',\n",
    "    'bsed' : 'SEM, backscatter',\n",
    "    'nbsed' : 'SEM, normalized backscatter',\n",
    "    'etd' : 'SEM, secondary electron',\n",
    "    'sed' : 'SEM, secondary electron',\n",
    "    'cl' : 'cathodoluminescence',\n",
    "    'al' : 'SEM x-ray map, Al',\n",
    "    'ca' : 'SEM x-ray map, Ca',\n",
    "    'cr' : 'SEM x-ray map, Cr',\n",
    "    'fe' : 'SEM x-ray map, Fe',\n",
    "    'k' : 'SEM x-ray map, K',\n",
    "    'mg' : 'SEM x-ray map, Mg',\n",
    "    'mn' : 'SEM x-ray map, Mn',\n",
    "    'na' : 'SEM x-ray map, Na',\n",
    "    'ni' : 'SEM x-ray map, Ni',\n",
    "    'o' : 'SEM x-ray map, O',\n",
    "    's' : 'SEM x-ray map, S',\n",
    "    'si' : 'SEM x-ray map, Si',\n",
    "    'ti' : 'SEM x-ray map, Ti'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .composite fn.s\n",
    "# from .composite import brighten\n",
    "def brighten(val, minval):\n",
    "    \"\"\"Brightens image based on minval\n",
    "\n",
    "    Args:\n",
    "        val (int): value of a single channel\n",
    "        minval (int): minimum channel value in the converted image. Used to\n",
    "            brighten or darken the composite.\n",
    "\n",
    "    Returns:\n",
    "        New channel value as int\n",
    "    \"\"\"\n",
    "    return minval + (255 - minval) * val / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .helpers fn.s\n",
    "# from .helpers import (cluster, cprint, mandolin, mogrify,\n",
    "#                       prompt, _guess_extension, _select_folder, IMAGE_MAP)\n",
    "\n",
    "import re\n",
    "\n",
    "def cluster(data, maxgap):\n",
    "    '''Group data such that successive elements differ by no more than maxgap\n",
    "\n",
    "       Based on http://stackoverflow.com/questions/14783947\n",
    "\n",
    "       Args:\n",
    "           data (list): list of numbers (either floats or integers)\n",
    "           maxgap (int): maximum acceptable gap between successive elements\n",
    "\n",
    "       Returns:\n",
    "           List of clusters\n",
    "    '''\n",
    "    data.sort()\n",
    "    groups = [[data[0]]]\n",
    "    for x in data[1:]:\n",
    "        if abs(x - groups[-1][-1]) <= maxgap:\n",
    "            groups[-1].append(x)\n",
    "        else:\n",
    "            groups.append([x])\n",
    "    return groups\n",
    "\n",
    "def cprint(s, show=True):\n",
    "    \"\"\"Prints string only if conditional is true\n",
    "\n",
    "    Args:\n",
    "        s (str): string to print\n",
    "        show (bool): specifies whether to print\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if bool(s) and show:\n",
    "        print (fill(s, subsequent_indent='  '))\n",
    "        \n",
    "def mandolin(lst, n):\n",
    "    \"\"\"Split list into groups of n members\n",
    "\n",
    "    Based on http://stackoverflow.com/questions/9671224/\n",
    "\n",
    "    Args:\n",
    "        lst (list): list containing anything you like\n",
    "        n (int): length of members\n",
    "\n",
    "    Returns:\n",
    "        List of lists of n members. The last value is padded\n",
    "        with empty strings to n if the original list is not\n",
    "        exactly divisible by n.\n",
    "    \"\"\"\n",
    "    n = int(n) #cast to int\n",
    "    mandolined = [lst[i*n:(i+1)*n] for i in range(len(lst) // n)]\n",
    "    remainder = len(lst) % n\n",
    "    if remainder:\n",
    "        leftovers = lst[-remainder:]\n",
    "        mandolined.append(leftovers + [''] * (n - len(leftovers)))\n",
    "    return mandolined\n",
    "\n",
    "def mogrify(path, ext):\n",
    "    \"\"\"Uses ImageMagick to copy source files to a working directory\n",
    "\n",
    "    Requires ImageMagick to be installed and on the system path.\n",
    "\n",
    "    Args:\n",
    "        path (str): filepath to directory containing images\n",
    "        ext (str): extension of files to copy from path\n",
    "\n",
    "    Returns:\n",
    "        True if mogrify command succeeds, False if not\n",
    "    \"\"\"\n",
    "    cprint('There was a problem opening some of the tiles!\\n'\n",
    "           'Copying tiles into a usable format...')\n",
    "    ext = ext.strip('*.')\n",
    "    subdir = os.path.join(path, 'working')\n",
    "    try:\n",
    "        os.mkdir(subdir)\n",
    "    except OSError:\n",
    "        pass\n",
    "    cmd = 'mogrify -path \"working\" -format {0} *.{0}'.format(ext)\n",
    "    args = shlex.split(cmd)\n",
    "    try:\n",
    "        subprocess.call(args, cwd=path)\n",
    "    except:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def prompt(prompt, validator, confirm=False,\n",
    "           helptext='No help text provided', errortext='Invalid response!'):\n",
    "    \"\"\"Prompts user and validates response based on validator\n",
    "\n",
    "    Args:\n",
    "        prompt (str or unicode): prompt to display to user\n",
    "        validator (str, list, or dict): object used to validate user\n",
    "            response\n",
    "        confirm (bool): specifies whether to have user verify response\n",
    "        helptext (str or unicode): text to display if user enters '?'\n",
    "        errortext (str or unicode): text to display if response\n",
    "            does not validate\n",
    "\n",
    "    Returns:\n",
    "        A unicode string containing the validated user input\n",
    "\n",
    "    Raises:\n",
    "        Unspecified error: Validator is not dict, list, or str\n",
    "    \"\"\"\n",
    "    # Prepare string\n",
    "    prompt = u'{} '.format(prompt.rstrip())\n",
    "    # Prepare validator\n",
    "    if isinstance(validator, (str)):\n",
    "        validator = re.compile(validator, re.U)\n",
    "    elif isinstance(validator, dict):\n",
    "        prompt = '{}({}) '.format(prompt, '/'.join(validator.keys()))\n",
    "    elif isinstance(validator, list):\n",
    "        options = ['{}. {}'.format(x + 1, validator[x])\n",
    "                   for x in range(0, len(validator))]\n",
    "    else:\n",
    "        input(fill('Error in stitch2d.helpers.prompt: '\n",
    "                       'Validator must be dict, list, or str.'))\n",
    "        raise\n",
    "    # Validate response\n",
    "    loop = True\n",
    "    while loop:\n",
    "        # Print options\n",
    "        if isinstance(validator, list):\n",
    "            print('{}\\n{}'.format('\\n'.join(options), '-' * 60))\n",
    "        # Prompt for value\n",
    "        a = input(prompt)#.decode(sys.stdin.encoding)\n",
    "        if a.lower() == 'q':\n",
    "            print('User exited prompt')\n",
    "            sys.exit()\n",
    "        elif a.lower() == '?':\n",
    "            print(fill(helptext))\n",
    "            loop = False\n",
    "        elif isinstance(validator, list):\n",
    "            try:\n",
    "                i = int(a) - 1\n",
    "                result = validator[i]\n",
    "            except:\n",
    "                pass\n",
    "            else:\n",
    "                if i >= 0:\n",
    "                    loop = False\n",
    "        elif isinstance(validator, dict):\n",
    "            try:\n",
    "                result = validator[a]\n",
    "            except:\n",
    "                pass\n",
    "            else:\n",
    "                loop = False\n",
    "        else:\n",
    "            try:\n",
    "                validator.search(a).group()\n",
    "            except:\n",
    "                pass\n",
    "            else:\n",
    "                result = a\n",
    "                loop = False\n",
    "        # Confirm value, if required\n",
    "        if confirm and not loop:\n",
    "            try:\n",
    "                result = unicode(result)\n",
    "            except:\n",
    "                result = str(result)\n",
    "            loop = prompt('Is this value correct: \"{}\"?'.format(result),\n",
    "                          {'y' : False, 'n' : True}, confirm=False)\n",
    "        elif loop:\n",
    "            print(fill(errortext))\n",
    "    # Return value as unicode\n",
    "    return result\n",
    "\n",
    "def _guess_extension(path):\n",
    "    \"\"\"Determines extension based on files in path\n",
    "\n",
    "    Args:\n",
    "        path (str): path to folder containing tiles\n",
    "\n",
    "    Returns:\n",
    "        File extension of first valid file type\n",
    "    \"\"\"\n",
    "    for fn in os.listdir(path):\n",
    "        ext = os.path.splitext(fn)[1]\n",
    "        try:\n",
    "            IMAGE_MAP[ext.lower()]\n",
    "        except KeyError:\n",
    "            pass\n",
    "        else:\n",
    "            return ext\n",
    "    else:\n",
    "        msg = (u'Could not find a valid tileset in {} Supported image'\n",
    "                ' formats include {}').format(path, sorted(IMAGE_MAP))\n",
    "        raise Exception(msg)\n",
    "        \n",
    "def _select_folder(title=('Please select the directory'\n",
    "                          ' containing your tilesets:')):\n",
    "    \"\"\"Select directory using GUI\n",
    "\n",
    "    Args:\n",
    "        title (str): title of GUI window\n",
    "\n",
    "    Returns:\n",
    "        Path as to directory as string\n",
    "    \"\"\"\n",
    "    root = tkinter.Tk()\n",
    "    root.withdraw()\n",
    "    return filedialog.askdirectory(parent=root, title=title,\n",
    "                                     initialdir=os.getcwd())\n",
    "\n",
    "def _get_coordinates(fn):\n",
    "    return tuple([int(c) for c in fn.split('@')[1].split(']')[0].split(' ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .offset class\n",
    "# from .offset import OffsetEngine\n",
    "\n",
    "import pyglet\n",
    "\n",
    "class OffsetEngine(pyglet.window.Window):\n",
    "    def __init__(self, rows, same_row=True, offsets=None, *args, **kwargs):\n",
    "        # Set window size in init because Windows doesn't pick up\n",
    "        # set_size() reliably.\n",
    "        platform = pyglet.window.get_platform()\n",
    "        display = platform.get_default_display()\n",
    "        screen = display.get_default_screen()\n",
    "        margin = 75\n",
    "        super(OffsetEngine, self).__init__(\n",
    "            *args,\n",
    "            width=screen.width - margin * 2,\n",
    "            height=screen.height - margin * 2,\n",
    "            visible=False,\n",
    "            **kwargs)\n",
    "        self.set_location(margin, margin)\n",
    "\n",
    "        self.rows = rows\n",
    "        self.num_cols = len(rows[0])\n",
    "        self.num_rows = len(rows)\n",
    "        # Coordinates increase from 0,0 in the upper left. Offsets\n",
    "        # are defined as follows:\n",
    "        #  Within row: y is positive if the top edge of the right\n",
    "        #   tile is HIGHER than that of the left (stair step up).\n",
    "        #   Because tiles must be shifted left to overlap, x\n",
    "        #   is always negative.\n",
    "        #  Between rows: x is positive if the left edge of the lower\n",
    "        #   tile is to the RIGHT of the left edge of the upper tile.\n",
    "        #   Because tiles must be shifted up to overlap, y is\n",
    "        #   always negative.\n",
    "        self.coordinates = []\n",
    "        if offsets:\n",
    "            try:\n",
    "                self.x_offset_within_row = offsets[0]\n",
    "                self.x_offset_between_rows = 0\n",
    "                self.y_offset_within_row = offsets[1]\n",
    "                self.y_offset_between_rows = 1\n",
    "            except IndexError:\n",
    "                print('Provided offsets no good')\n",
    "        else:\n",
    "            self.x_offset_within_row = 1  # final value should be <= 0\n",
    "            self.x_offset_between_rows = 0\n",
    "            self.y_offset_within_row = 0\n",
    "            self.y_offset_between_rows = 0  # final value should be <= 0\n",
    "\n",
    "        self.hand = self.get_system_mouse_cursor(self.CURSOR_HAND)\n",
    "        self.crosshair = self.get_system_mouse_cursor(self.CURSOR_CROSSHAIR)\n",
    "        self.set_mouse_cursor(self.crosshair)\n",
    "\n",
    "        self.guidance = [\n",
    "            ('Click any distinct feature that appears on both sides'\n",
    "             ' of the boundary, or try the arrow keys for minor'\n",
    "             ' adjustsments'),\n",
    "            ('Click the corresponding feature on the other side'\n",
    "             ' of the boundary'),\n",
    "            ('Use the arrow keys to adjust the offset or click reset'\n",
    "             ' to start over')\n",
    "              ]\n",
    "        self.orig_guidance = copy(self.guidance)\n",
    "\n",
    "        self.same_row = same_row\n",
    "        if self.same_row:\n",
    "            self.set_caption('Set offset between tiles in the same row')\n",
    "        else:\n",
    "            self.set_caption('Set offset between tiles in different rows')\n",
    "\n",
    "        self.n_row = 0\n",
    "        self.n_col = 0\n",
    "\n",
    "        self.color = (255,255,255,255)\n",
    "        self.label_batch = pyglet.graphics.Batch()\n",
    "        self.labels = {}\n",
    "        self.labels['guidance'] = pyglet.text.Label(\n",
    "            self.guidance.pop(0),\n",
    "            width = self.width / 2,\n",
    "            align = 'center',\n",
    "            multiline = True,\n",
    "            x = self.width / 2,\n",
    "            y = self.height - 8,\n",
    "            anchor_x='center',\n",
    "            anchor_y='top',\n",
    "            batch=self.label_batch)\n",
    "        self.labels['offset'] = pyglet.text.Label(\n",
    "            '{}x{}'.format(self.x_offset_within_row, self.y_offset_within_row),\n",
    "            x = self.width / 2,\n",
    "            y = 8,\n",
    "            anchor_x='center',\n",
    "            anchor_y='bottom',\n",
    "            batch=self.label_batch)\n",
    "        self.labels['new'] = pyglet.text.Label(\n",
    "            'Get different tiles',\n",
    "            x = self.width - 8,\n",
    "            y = self.height - 8,\n",
    "            anchor_x='right',\n",
    "            anchor_y='top',\n",
    "            batch=self.label_batch)\n",
    "        self.labels['reset'] = pyglet.text.Label(\n",
    "            'Reset offset',\n",
    "            x = 8,\n",
    "            y = self.height - 8,\n",
    "            anchor_x='left',\n",
    "            anchor_y='top',\n",
    "            batch=self.label_batch)\n",
    "        self.labels['save'] = pyglet.text.Label(\n",
    "            'Save and return',\n",
    "            x = self.width - 8,\n",
    "            y = 8,\n",
    "            anchor_x='right',\n",
    "            anchor_y='bottom',\n",
    "            batch=self.label_batch)\n",
    "        self.labels['coordinates'] = pyglet.text.Label(\n",
    "            'Tile: {}x{}'.format(self.n_row, self.n_col),\n",
    "            x = 8,\n",
    "            y = 8,\n",
    "            anchor_x='left',\n",
    "            anchor_y='bottom',\n",
    "            batch=self.label_batch)\n",
    "        for key in self.labels:\n",
    "            self.labels[key].bold = True\n",
    "            self.labels[key].color = self.color\n",
    "\n",
    "        self.get_tiles()\n",
    "        self.set_visible(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mosaic(object):\n",
    "    \"\"\"Contains functions and metadata needed to create a mosaic from a tilset\n",
    "\n",
    "    Class attributes describe the tiles and tileset and are\n",
    "    populated using :py:func:`~Stitch2D.mosaic.populate_tiles`.\n",
    "    To make a mosaic, use :py:func:`~Stitch2D.mosaic.prepare_mosaic`\n",
    "    to calculate the coordinates, then pass the coordinates to\n",
    "    :py:func:`~Stitch2D.mosaic.create_mosaic` to stitch.\n",
    "\n",
    "    Attributes:\n",
    "        grid (list): specifies position of tiles in grid\n",
    "        dim (tuple): number of (columns, rows) in the tileset\n",
    "        size (tuple): (width, height) of individual tiles\n",
    "        mag (float): magnification of images\n",
    "        snake (bool): specifies snake pattern\n",
    "        coordinates (dict): coordinates of tiles in mosaic keyed\n",
    "            to filepaths\n",
    "        keypoints (dict): keypoints detected by OpenCV keyed to\n",
    "            filepaths\n",
    "        fill (tuple): fill color of background. Default is black.\n",
    "        text (tuple): color of text. Default is inverse of fill.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path, output='.', param_file=None, skip_file=None,\n",
    "                 label=None,num_cols=1, **kwargs):\n",
    "        \"\"\"Initialize new Tileset\n",
    "\n",
    "        The heavy lifting is done by\n",
    "        :py:func:`~Stitch2d.Mosaic.populate_tiles()`,\n",
    "        which populates and processes the tileset.\n",
    "\n",
    "        Args:\n",
    "            path (str): path to tileset\n",
    "            param_file (str): filepath to parameters file\n",
    "            skip_file (str): path to file containing indices of skipped tiles\n",
    "        \"\"\"\n",
    "#         self.basepath = wdir#os.path.dirname(__file__)\n",
    "        try:\n",
    "            os.makedirs(output)\n",
    "        except OSError:\n",
    "            pass\n",
    "\n",
    "        self.output = output\n",
    "        self.normal = True\n",
    "        self.verbose = False\n",
    "        self.fill = (0,0,0)\n",
    "        self.text = tuple([(255 - x) for x in self.fill])\n",
    "\n",
    "        self.populate_tiles(path, param_file, skip_file, label, num_cols=1, **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def populate_tiles(self, path, param_file=None, skip_file=None,\n",
    "                       label=None,num_cols=1,snake=True, **kwargs):\n",
    "        \"\"\"Test, characterize, sort and patch tiles from path\n",
    "\n",
    "        Args:\n",
    "            path (str): filepath to tiles\n",
    "            param_file (str): filepath to parameters file\n",
    "            skip_file (str): filepath to text file containing the\n",
    "                list of skipped indices\n",
    "            label (str): name of the mosaic (typically the sample name)\n",
    "            num_columns (int): number of columns in the mosaic\n",
    "            snake (bool): specifies whether mosaic is a snake pattern\n",
    "            smooth (bool): specifies whether to try to smooth out boundaries\n",
    "                between images\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        # Get extension\n",
    "        try:\n",
    "            ext = _guess_extension(path)\n",
    "        except KeyError:\n",
    "            if param_file is None:\n",
    "                raise\n",
    "            else:\n",
    "                self.grid = {}\n",
    "                return self\n",
    "\n",
    "        # Get descriptive name of tileset based on filename\n",
    "        fn = os.path.splitext(os.path.basename(path))[0]\n",
    "        name = label if label is not None else fn\n",
    "        try:\n",
    "            base, kind = fn.rsplit('_', 1)\n",
    "        except ValueError:\n",
    "            kind = None\n",
    "            blurb = None\n",
    "        else:\n",
    "            while kind and kind[0].isdigit():\n",
    "                kind = kind[1:]\n",
    "            blurb = IMAGE_TYPES.get(kind.lower())\n",
    "            if blurb is None and 1 <= len(kind) <= 2:\n",
    "                blurb = kind.lower().capitalize()\n",
    "        fn = name.replace(' ', '_') if label is not None else fn\n",
    "        if kind is not None:\n",
    "            fn += '_{}'.format(kind)\n",
    "        if blurb is not None:\n",
    "            name += ' ({})'.format(blurb)\n",
    "        self.filename = fn.replace('(', '').replace(')', '').replace('.', 'pt')\n",
    "        self.name = name\n",
    "        cprint('{} => {}'.format(self.name, self.filename), self.normal)\n",
    "\n",
    "        print(\"Testing path\",path)\n",
    "        \n",
    "        #path = self._test_file(path)\n",
    "        self.dim = (0, 0)\n",
    "\n",
    "        tiles = glob.glob(os.path.join(path, '*' + ext))\n",
    "        tiles = self._sort(tiles)  # calculates self.dim[0] if it can\n",
    "        print ('The tileset contains',len(tiles),'tiles')\n",
    "        # Set self.size to the LARGEST tile size. If multiple sizes are\n",
    "        # present, resize and manual options are forbidden.\n",
    "        sizes = [Image.open(tile).size for tile in tiles[:5]]\n",
    "        self.size = (max([size[0] for size in sizes]),\n",
    "                     max([size[1] for size in sizes]))\n",
    "        if len(set(sizes)) > 1:\n",
    "            print('Tiles are not uniform in size!')\n",
    "\n",
    "        try:\n",
    "            params = serialize.load(open(param_file, 'r'))\n",
    "        except (IOError, TypeError):\n",
    "            # Get parameters from kwarg\n",
    "            minval = kwargs.get('minval')\n",
    "            #num_cols = kwargs.get('num_cols')\n",
    "            snake = kwargs.get('snake')\n",
    "            smooth = kwargs.get('smooth')\n",
    "            blur = kwargs.get('blur', 0)\n",
    "            # Prompt for missing params and assign to attributes\n",
    "            review = num_cols is None or snake is None\n",
    "            cprint('Set tileset parameters:')\n",
    "            if not self.dim[0] and num_cols is None:\n",
    "                num_cols = int(prompt(' Number of columns:', '^\\d+$'))\n",
    "            elif num_cols is None:\n",
    "                review = snake is None\n",
    "                num_cols = self.dim[0]\n",
    "                cprint((' Number of columns: {} (determined from'\n",
    "                        ' filenames)').format(num_cols))\n",
    "            #self.mag = float(prompt(' Magnification:', '^\\d+(\\.\\d)?$'))\n",
    "            #if snake is None:\n",
    "                #snake = prompt(' Snake pattern?', {'y' : True, 'n' : False})\n",
    "            self.snake = snake\n",
    "            self.smooth = True #if smooth else False\n",
    "            self.minval = minval if minval is not None else 0\n",
    "            self.blur = blur\n",
    "        else:\n",
    "            review = False\n",
    "            num_cols = params['num_cols']\n",
    "            self.minval = params['minval']\n",
    "            self.snake = params['snake']\n",
    "            self.smooth = params['smooth']\n",
    "            self.blur = params['blur']\n",
    "\n",
    "        skiplist = []\n",
    "        if skip_file is not None:\n",
    "            skiplist = self._handle_skipped(skip_file)\n",
    "        tiles = self._patch(tiles, skiplist)\n",
    "\n",
    "        # Pad the grid\n",
    "        rows = {}\n",
    "        for tile in tiles:\n",
    "            #from .helpers import _get_coordinates\n",
    "            try:\n",
    "                row, col = _get_coordinates(tile)\n",
    "            except IndexError:\n",
    "                row = len(rows)\n",
    "                if len(rows.get(row, [])) == num_cols:\n",
    "                    row += 1\n",
    "            rows.setdefault(row, []).append(tile)\n",
    "        max_tiles = max([len(row) for row in rows.values()])\n",
    "        longest_row = [len(row) for i, row in rows.items() if len(row) == max_tiles][0]\n",
    "        longest_row = 0\n",
    "        for row, cols in rows.items():\n",
    "            while len(cols) < longest_row:\n",
    "                print(longest_row)\n",
    "                cols.append(None)\n",
    "        #print longest_row\n",
    "        #input()\n",
    "\n",
    "        self.grid = mandolin(tiles, num_cols)\n",
    "        self.dim = (num_cols, len(self.grid))\n",
    "        if self.snake:\n",
    "            self.grid = self._desnake(self.grid, self.snake)\n",
    "\n",
    "        # Review parameters, allowing user to try again if the parameters\n",
    "        # are not suitable\n",
    "        cprint('Mosaic parameters:')\n",
    "        cprint(' Dimensions:     {}x{}'.format(self.dim[0], self.dim[1]))\n",
    "        #cprint(' Magnification:  {}'.format(self.mag))\n",
    "        cprint(' Snake:          {}'.format(self.snake))\n",
    "        cprint(' Smooth:         {}'.format(self.smooth))\n",
    "        cprint(' Blur radius:    {}'.format(self.blur))\n",
    "        cprint(' Minimum pixel:  {}'.format(self.minval))\n",
    "#         if review and not prompt('Confirm', {'y' : True, 'n' : False}):\n",
    "#             self.populate_tiles(path, ext, param_file, skip_file, label)\n",
    "#             print(\"DEBUG: Review and not Prompt\")\n",
    "#         else:\n",
    "        self.keypoints = {}\n",
    "        print(\"DEBUG: Populate Tiles Return\")\n",
    "        return self\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _test_file(self, path):\n",
    "        \"\"\"Test first tile in tileset to confirm PIL can open it\n",
    "\n",
    "        If the image fails to open, this function will try\n",
    "        to mogrify a usable copy in path/working. This requires\n",
    "        ImageMagick.\n",
    "\n",
    "        Args:\n",
    "            path (str): filepath to tiles\n",
    "            ext (str): extension on image files\n",
    "\n",
    "        Returns:\n",
    "            Path to set of images\n",
    "        \"\"\"\n",
    "        for fp in glob.iglob(os.path.join(path, '*')):\n",
    "            ext = os.path.splitext(fp)[1]\n",
    "            try:\n",
    "                Image.open(fp)\n",
    "            except IOError:\n",
    "                # This is a clumsy solution to PIL's unreliability\n",
    "                # reading TIFFs. It uses ImageMagick to copy\n",
    "                # the unreadable tiles to a subdirectory; the\n",
    "                # IM-created tiles should always be readable by PIL.\n",
    "                if ext in IMAGE_MAP and mogrify(path, ext):\n",
    "                    path = os.path.join(path, 'working')\n",
    "                else:\n",
    "                    cprint('1 Encountered unreadable tiles but could'\n",
    "                           ' not fix them. Try installing ImageMagick'\n",
    "                           ' and re-running this script.')\n",
    "                    sys.exit()\n",
    "            break\n",
    "        return path\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _sort(self, tiles):\n",
    "        \"\"\"Identifies iterator in tileset and sorts\n",
    "\n",
    "        The sort function works by detecting the iterator, which\n",
    "        is the part of the filename that changes between files\n",
    "        in the same tileset. Typically the interator will be an\n",
    "        integer (abc-1.jpg or abc-001.jpg) or a column-row pair\n",
    "        (abc_Grid[@0 0].jpg).\n",
    "\n",
    "        Args:\n",
    "            tiles (list): filepaths of all tiles as strings\n",
    "\n",
    "        Returns:\n",
    "            A sorted list of filepaths representing tiles, with\n",
    "            empty strings where the tileset was patched.\n",
    "        \"\"\"\n",
    "        # Identify this iterator by finding which parts change across\n",
    "        # the tileset.\n",
    "        starts_with = []\n",
    "        ends_with = []\n",
    "        i = 0\n",
    "        while i < len(tiles):\n",
    "            j = 0\n",
    "            while tiles[i][j] == tiles[i-1][j]:\n",
    "                j += 1\n",
    "            starts_with.append(j)\n",
    "            j = 0\n",
    "            while tiles[i][::-1][j] == tiles[i-1][::-1][j]:\n",
    "                j += 1\n",
    "            ends_with.append(j)\n",
    "            i += 1\n",
    "        starts = tiles[0][:min(starts_with)]\n",
    "        ends = tiles[0][len(tiles[0])-min(ends_with):]\n",
    "        # Now we handle the two cases described above (number and\n",
    "        # column-row pair). Note that the script is quite simple\n",
    "        # in its handling of coordinates--for example, it does not\n",
    "        # handle row-column pairs or column-row pairs joined by an \"x.\"\n",
    "        temp = {}\n",
    "        cols = []\n",
    "        e = None\n",
    "        for tile in tiles:\n",
    "            key = tile.replace(starts, '', 1).replace(ends, '', 1)\n",
    "            try:\n",
    "                # Special case: SEM grid notation. We can use the\n",
    "                # coordinates in the grid to calculate the number\n",
    "                # of columns.\n",
    "                x, y = key.split(' ')\n",
    "                cols.append(int(x))\n",
    "                i = key\n",
    "            except ValueError:\n",
    "                try:\n",
    "                    i = int(key)\n",
    "                except ValueError:\n",
    "                    i = key\n",
    "                    # Typically caused by alien tiles in the tileset\n",
    "                    #e = ('Warning: Could not sort tiles. Please'\n",
    "                    #     ' confirm that there are no extra tiles'\n",
    "                    #     ' in the source folder.')\n",
    "            temp[i] = tile\n",
    "        cprint(e)\n",
    "        if len(cols) and not self.dim[1]:\n",
    "            num_cols = max(cols) + 1\n",
    "            for key in temp.keys():\n",
    "                x, y = key.split(' ')\n",
    "                i = int(x) + num_cols * int(y)\n",
    "                temp[i] = temp[key]\n",
    "                del temp[key]\n",
    "            self.dim = (num_cols, self.dim[1])\n",
    "        # Create tiles and rows\n",
    "        tiles = [temp[key] for key in sorted(temp.keys())]\n",
    "        #tiles.sort()\n",
    "        for tile in tiles: print(tile)\n",
    "        return tiles\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _patch(self, tiles, skiplist=[]):\n",
    "        \"\"\"Patches tileset based on list of skipped tiles\n",
    "\n",
    "        Args:\n",
    "            tiles (list): list of tiles\n",
    "            skiplist (list): list of indices (not filenames) from\n",
    "                the master tileset that have been excluded by the\n",
    "                user\n",
    "\n",
    "        Returns:\n",
    "            Sorted list of tiles with empty strings at indices\n",
    "            where tiles were missing.\n",
    "        \"\"\"\n",
    "        if not len(skiplist):\n",
    "            return tiles\n",
    "        else:\n",
    "            # Get dimensions of the tileset from skipped file, then\n",
    "            # check length of tiles against the number of skipped tiles\n",
    "            # to see if anything's missing.\n",
    "            dim = skiplist[0].split(': ', 1)[1].strip()\n",
    "            self.dim =  tuple([int(x) for x in dim.split('x')])\n",
    "            remainder = len(tiles) % self.dim[0]\n",
    "            n = self.dim[0] * self.dim[1]\n",
    "            if n == len(tiles) + (self.dim[0] - remainder):\n",
    "                for i in skiplist[1:]:\n",
    "                    tiles[i] = ''\n",
    "                return tiles\n",
    "        # Insert blanks where they should fall in the tile sequence,\n",
    "        # then fill the tiles around them.\n",
    "        sequence = {}\n",
    "        for i in skiplist[1:]:\n",
    "            sequence[i] = ''\n",
    "        i = 0\n",
    "        for tile in tiles:\n",
    "            while True:\n",
    "                try:\n",
    "                    sequence[i]\n",
    "                except KeyError:\n",
    "                    sequence[i] = tile\n",
    "                    break\n",
    "                else:\n",
    "                    i += 1\n",
    "        tiles = []\n",
    "        for i in sorted(sequence.keys()):\n",
    "            tiles.append(sequence[i])\n",
    "        cprint('Tile set was patched!')\n",
    "        # Check for missing tiles\n",
    "        if len(tiles) < n:\n",
    "            print ('However,',n-len(tiles),'tiles appear to be missing')\n",
    "        return tiles\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _missing(self, tiles):\n",
    "        \"\"\"Check tilset for missing tiles by analyzing keys\n",
    "\n",
    "        Ars:\n",
    "            tiles (dict): collection of tiles keyed to their index in\n",
    "                the grid before desnaking\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        keys = tiles.keys()\n",
    "        idealized_keys = set([x for x in range(min(keys), max(keys)+1)])\n",
    "        missing = idealized_keys - set(keys)\n",
    "        empties = [tile for tile in tiles if not bool(tile)]\n",
    "        if len(missing) and not len(empties):\n",
    "            cprint('Warning: The following tiles appear to be missing:')\n",
    "            for key in sorted(missing):\n",
    "                cprint(' Index {}'.format(key))\n",
    "                tiles.insert(key-1, '')\n",
    "        else:\n",
    "            cprint('All tiles appear to be present')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _desnake(self, grid, pattern):\n",
    "        \"\"\"Reorders tiles to account for snake pattern\n",
    "\n",
    "        Args:\n",
    "            grid (list): grid of tiles\n",
    "            pattern (bool): specifies if snake pattern\n",
    "\n",
    "        Returns:\n",
    "            List containing the tile grid corrected for snaking\n",
    "        \"\"\"\n",
    "        if pattern:\n",
    "            return [grid[i][::-1] if i % 2 else grid[i]\n",
    "                    for i in range(0, len(grid))]\n",
    "        return tiles\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _handle_skipped(self, skip_file):\n",
    "        \"\"\"Read indices of skipped tiles from file\n",
    "\n",
    "        Args:\n",
    "            skip_file (str): filepath to text file containing the\n",
    "                list of skipped indices\n",
    "\n",
    "        Returns:\n",
    "            A list of indices used to patch the tileset\n",
    "        \"\"\"\n",
    "        try:\n",
    "            f = open(os.path.join(skip_file), 'r')\n",
    "        except OSError:\n",
    "            raise OSError\n",
    "        else:\n",
    "            try:\n",
    "                return [int(i.strip()) if i.isdigit() else i.strip()\n",
    "                        for i in f.read().splitlines()]\n",
    "            except TypeError:\n",
    "                raise TypeError\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def prepare_mosaic(self, param_file=None, opencv=True, **kwargs):\n",
    "        \"\"\"Determines coordinates for tiles based on tileset metadata\n",
    "\n",
    "        Args:\n",
    "            param_file (str): filepath to parameters file`\n",
    "            opencv (bool): specifies whether to use OpenCV. If\n",
    "                OpenCV is not installed, will switch to manual.\n",
    "            kwargs: see :py:func:`~Stitch2D.Mosaic.mosey`\n",
    "                for additional keywords\n",
    "\n",
    "        Returns:\n",
    "            A dict of coordinates keyed to filepath\n",
    "        \"\"\"\n",
    "        # Confirm that OpenCV is installed and working properly\n",
    "#         if opencv:\n",
    "#             try:\n",
    "#                 cv2.imread(os.path.join(self.basepath, 'files', 'test.png'), 0)\n",
    "#             except NameError:\n",
    "#                 cprint('Could not find OpenCV! Switching to manual stitch.')\n",
    "#                 opencv = False\n",
    "\n",
    "        try:\n",
    "            params = serialize.load(open(param_file, 'r'))\n",
    "        except (IOError, TypeError):\n",
    "            if opencv:\n",
    "                cprint('Using OpenCV to stitch mosaic')\n",
    "                defaults = {\n",
    "                    'equalize_histogram' : False,\n",
    "                    'matcher' : 'brute-force',\n",
    "                    'homography' : False,\n",
    "                    'scalar' : 0.5,\n",
    "                    'threshold' : 1,\n",
    "                }\n",
    "                cv_params = {}\n",
    "                for key in defaults:\n",
    "                    cv_params[key] = kwargs.get(key, defaults[key])\n",
    "                cprint('  Equalize histogram: {}'.format(\n",
    "                            cv_params['equalize_histogram']))\n",
    "                cprint('  Matcher:            {}'.format(cv_params['matcher']))\n",
    "                cprint('  Homography:         {}'.format(\n",
    "                            cv_params['homography']))\n",
    "                cprint('  Scalar:             {}'.format(cv_params['scalar']))\n",
    "                cprint('  Threshold:          {}'.format(\n",
    "                            cv_params['threshold']))\n",
    "                cprint('Determining offset...')\n",
    "                posdata = self._cv_coordinates(**cv_params)\n",
    "            else:\n",
    "                cprint('Setting offset...')\n",
    "                posdata = self._set_coordinates()\n",
    "            # Record job parameters to file\n",
    "            params = [\n",
    "                self.filename,\n",
    "                '-' * len(self.filename),\n",
    "                'Dimensions: {}x{}'.format(self.dim[0], self.dim[1]),\n",
    "                #'Magnification: {}'.format(self.mag),\n",
    "                'Snake: {}'.format(self.snake),\n",
    "                'Smooth: {}'.format(self.smooth),\n",
    "                'Blur radius: {}'.format(self.blur),\n",
    "                'Minimum pixel: {}'.format(self.minval),\n",
    "                ''\n",
    "            ]\n",
    "            if opencv:\n",
    "                params.extend([\n",
    "                    'Autostitch: {}'.format(opencv),\n",
    "                    'Equalize histogram: {}'.format(\n",
    "                        cv_params['equalize_histogram']),\n",
    "                    'Matcher: {}'.format(cv_params['matcher']),\n",
    "                    'Homography: {}'.format(cv_params['homography']),\n",
    "                    'Scalar: {}'.format(cv_params['scalar']),\n",
    "                    'Threshold: {}'.format(cv_params['threshold']),\n",
    "                    ''\n",
    "                    ])\n",
    "            coordinates = posdata['coordinates']\n",
    "            params.append('Tile coordinates:')\n",
    "            keys = sorted(coordinates.keys(), key=lambda s:\n",
    "                            'x'.join(['0'*(4-len(n))+n\n",
    "                            for n in s.split('x')][::-1]))\n",
    "            for key in keys:\n",
    "                params.append('{}: {}'.format(key, coordinates[key]))\n",
    "            fp = os.path.join(self.output, self.filename + '.txt')\n",
    "            with open(fp, 'w') as f:\n",
    "                f.write('\\n'.join(params))\n",
    "            # Pickle key parameters for re-use later\n",
    "            params = {\n",
    "                'posdata' : posdata,\n",
    "                'minval': self.minval,\n",
    "                'num_cols': self.dim[0],\n",
    "                #'mag' : self.mag,\n",
    "                'snake': self.snake,\n",
    "                'smooth': self.smooth,\n",
    "                'blur': self.blur\n",
    "            }\n",
    "            param_file = \"params.json\"\n",
    "            print(\"Debug:\",param_file)\n",
    "            with open(param_file, 'w') as f:\n",
    "                serialize.dump(params, f)\n",
    "        else:\n",
    "            cprint('Found parameters file')\n",
    "            posdata = params['posdata']\n",
    "        return posdata\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def create_mosaic(self, posdata, opath, label=True, create_jpeg=True):\n",
    "        \"\"\"Draws mosaic based on the tile coordinates\n",
    "\n",
    "        Args:\n",
    "            posdata (dict): positional data for tiles\n",
    "            label (bool): specifies whether to include a label\n",
    "                at the bottom of the final mosaic\n",
    "            create_jpeg (bool): specifies whether to create a\n",
    "                half-size JPEG derivative of the final mosaic\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        # Normalize coordinates and calculate dimensions. The\n",
    "        # dimensions of the mosaic are determined by the tile\n",
    "        # dimensions minus the offsets between rows and columns\n",
    "        # Some general notes:\n",
    "        #  * Coordinates increase from (0,0) in the top left corner\n",
    "        #  * Offsets are always applied as n - 1 because they occur\n",
    "        #    between tiles.\n",
    "        start_time = datetime.now()\n",
    "\n",
    "        coordinates = posdata['coordinates']\n",
    "        overlaps = posdata['overlaps']\n",
    "\n",
    "        grid = self.grid\n",
    "        w, h = self.size\n",
    "\n",
    "        mosaic_width = max([coordinate[0] for coordinate in\n",
    "                            coordinates.values()]) + w\n",
    "        mosaic_height = max([coordinate[1] for coordinate in\n",
    "                             coordinates.values()]) + h\n",
    "        if label:\n",
    "            label_height = int(mosaic_height * 0.04)\n",
    "            mosaic_height += label_height\n",
    "        cprint('Mosaic will be {:,} by {:,}'\n",
    "               ' pixels'.format(mosaic_width, mosaic_height))\n",
    "        # Create the mosaic\n",
    "        cprint('Stitching mosaic...')\n",
    "        # Group the tiles by size\n",
    "        tiles = []\n",
    "        n_row = 0\n",
    "        while n_row < len(grid):\n",
    "            row = grid[n_row]\n",
    "            n_col = 0\n",
    "            while n_col < len(row):\n",
    "                position = '{}x{}'.format(n_col, n_row)\n",
    "                try:\n",
    "                    x, y = coordinates[position]\n",
    "                except KeyError:\n",
    "                    pass\n",
    "                else:\n",
    "                    fp = grid[n_row][n_col]\n",
    "                    path = os.path.dirname(fp)\n",
    "                    size = Image.open(fp).size\n",
    "                    area = size[0] * size[1]\n",
    "                    tiles.append([area, fp, (x, y)])\n",
    "                n_col += 1\n",
    "            n_row += 1\n",
    "        # Create a lookup from overlaps\n",
    "        lookup = {}\n",
    "        for t1, t2 in overlaps:\n",
    "            data = {tuple(t1[0]): t1[1], tuple(t2[0]): t2[1]}\n",
    "            for key in data:\n",
    "                lookup.setdefault(key, []).append(data)\n",
    "        # Normalize colors by comparing overlaps between adjacent tiles,\n",
    "        # building out from the middle of the mosaic to minimize edge effects\n",
    "        if self.smooth:\n",
    "            scalars = {}\n",
    "            found = []\n",
    "            n_row = len(grid) / 2\n",
    "            n_col = len(row) / 2\n",
    "            roots = [(n_col, n_row)]  # pos in overlap is like this I guess\n",
    "            while True:\n",
    "                neighbors = []\n",
    "                for root in roots:\n",
    "                    found.append(root)\n",
    "                    scalars.setdefault(root, 1.)\n",
    "                    n_col, n_row = root\n",
    "                    fp_root = grid[int(n_row)][int(n_col)]\n",
    "                    im_root = Image.open(fp_root).convert('RGB')\n",
    "                    if self.blur:\n",
    "                        im_root = im_root.filter(\n",
    "                            ImageFilter.GaussianBlur(self.blur)\n",
    "                            )\n",
    "                    # Scale neighbors\n",
    "                    for neighbor in lookup.get(root, []):\n",
    "                        coords = [coords for coords in neighbor.keys()\n",
    "                                  if coords != root][0]\n",
    "                        dim1 = neighbor[root]\n",
    "                        dim2 = neighbor[coords]\n",
    "                        n_col, n_row = coords\n",
    "                        try:\n",
    "                            fp2 = grid[n_row][n_col]\n",
    "                        except (IndexError, KeyError):\n",
    "                            pass\n",
    "                        else:\n",
    "                            im2 = Image.open(fp2).crop(dim2).convert('RGB')\n",
    "                            if self.blur:\n",
    "                                im2 = im2.filter(\n",
    "                                    ImageFilter.GaussianBlur(self.blur)\n",
    "                                    )\n",
    "                            m2 = np.array(im2).mean() * scalars.get(fp2, 1.)\n",
    "                            # Crop root tile to dimensions of overlap\n",
    "                            im1 = im_root.crop(dim1)\n",
    "                            m1 = np.array(im1).mean() * scalars.get(fp_root, 1.)\n",
    "                            # Set scalar for neighbor, if not already set\n",
    "                            scalars.setdefault(fp2, m1 / m2)\n",
    "                            if not coords in found:\n",
    "                                neighbors.append(coords)\n",
    "                roots = list(set(neighbors))\n",
    "                if not roots:\n",
    "                    break\n",
    "        # Paste tiles. If tiles are not uniform in size, paste them in\n",
    "        # order of increasing size. This is intended to resolve an issue\n",
    "        # with artifacts when using by cropped images.\n",
    "        mosaic = Image.new('RGB', (mosaic_width, mosaic_height), self.fill)\n",
    "        for tile in tiles[::-1]:\n",
    "            area, fp, coordinates = tile\n",
    "            try:\n",
    "                im = Image.open(fp.encode('cp1252')).convert('RGB')\n",
    "            except UnicodeDecodeError:\n",
    "                im = Image.open(fp).convert('RGB')\n",
    "            except OSError:\n",
    "                cprint('2 Encountered unreadable tiles but'\n",
    "                       ' could not fix them. Try installing'\n",
    "                       ' ImageMagick and re-running this'\n",
    "                       ' script.')\n",
    "                sys.exit()\n",
    "            # Adjust colors if smooth is specified\n",
    "            if self.blur:\n",
    "                im = im.filter(ImageFilter.GaussianBlur(self.blur))\n",
    "            if self.smooth or self.minval:\n",
    "                data = np.array(im).astype(np.float64)\n",
    "                if self.smooth:\n",
    "                    data[data > 0] *= scalars.get(fp, 1.)\n",
    "                if self.minval:\n",
    "                    data[data > 0] = np.apply_along_axis(brighten, 0,\n",
    "                                                         data[data > 0],\n",
    "                                                         minval=self.minval)\n",
    "                data[data > 255] = 255\n",
    "                im = Image.fromarray(data.astype(np.uint8))\n",
    "            mosaic.paste(im, coordinates)\n",
    "        # (*Don't) Add label\n",
    "#         if label:\n",
    "#             ttf = os.path.join(self.basepath, 'files', 'OpenSans-Regular.ttf')\n",
    "#             text = self.name\n",
    "#             text = text[0].upper() + text[1:]\n",
    "#             draw = ImageDraw.Draw(mosaic)\n",
    "#             # Resize text to a reasonable size based on the\n",
    "#             # dimensions of the mosaic\n",
    "#             size = 100\n",
    "#             font = ImageFont.truetype(ttf, size)\n",
    "#             w, h = font.getsize(text)\n",
    "#             size = int(0.8 * size * label_height / float(h))\n",
    "#             font = ImageFont.truetype(ttf, size)\n",
    "#             x = int(0.02 * mosaic_width)\n",
    "#             y = mosaic_height - int(label_height)\n",
    "#             #draw.text((x, y), text, self.text, font=font) # disabled caption\n",
    "#         cprint('Saving as {}...'.format('TIFF'))\n",
    "        #fp = os.path.join(self.path, os.pardir, self.filename + '.tif')\n",
    "#         fp = os.path.join(self.output, self.filename + '.png')\n",
    "#         mosaic.save(fp, 'PNG')\n",
    "#         if create_jpeg:\n",
    "        cprint('Saving as JPEG...')\n",
    "        fp = opath + '\\\\_stitched.jpg'\n",
    "#             try:\n",
    "#                 mosaic = mosaic.resize((mosaic_width / 2, mosaic_height / 2))\n",
    "#             except:\n",
    "#                 print('Failed to resize JPEG. Creating full-size instead.')\n",
    "#                 pass\n",
    "        mosaic.save(fp, 'JPEG', quality=92)\n",
    "        cprint('Mosaic complete! (t={})'.format(datetime.now() - start_time))\n",
    "        if path.rstrip('/').endswith('working'):\n",
    "            try:\n",
    "                shutil.rmtree(path)\n",
    "            except OSError:\n",
    "                pass\n",
    "        return True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _set_coordinates(self):\n",
    "        \"\"\"Allows user to set offsets and coordinates using GUI\n",
    "\n",
    "        Calls :py:func:`~Stitch2D.offset.OffsetEngine` to determine\n",
    "        offset within and between rows. The same offset is used across\n",
    "        the entire grid, so this will produce a useful but imperfect\n",
    "        mosaic.\n",
    "\n",
    "        Returns:\n",
    "            A dict of coordinates specifying the placement of\n",
    "            tiles on the final mosaic\n",
    "        \"\"\"\n",
    "        grid = self.grid\n",
    "        dim = self.dim\n",
    "        w, h = self.size\n",
    "\n",
    "        # Use the offset engine to allow users to set the offsets\n",
    "        engine = OffsetEngine(grid, True)\n",
    "        offset = engine.set_offset()\n",
    "        engine = OffsetEngine(grid, False, offset)\n",
    "        offset = engine.set_offset()\n",
    "\n",
    "        x_offset_within_row = offset[0]\n",
    "        y_offset_within_row = offset[1]\n",
    "        x_offset_between_rows = offset[2]\n",
    "        y_offset_between_rows = offset[3]\n",
    "\n",
    "        coordinates = {}\n",
    "        n_row = 0  # index of row\n",
    "        for row in grid:\n",
    "            n_col = 0  # index of column\n",
    "            for fp in row:\n",
    "                if bool(fp):\n",
    "                    # Calculate x coordinate\n",
    "                    x = ((w + x_offset_within_row) * n_col +\n",
    "                         x_offset_between_rows * n_row)\n",
    "                    if x_offset_between_rows < 0:\n",
    "                        x -= x_offset_between_rows * (dim[1] - 1)\n",
    "                    # Calculate y coordinate\n",
    "                    y = ((h + y_offset_between_rows) * n_row +\n",
    "                         y_offset_within_row * n_col)\n",
    "                    if y_offset_within_row < 0:\n",
    "                        y -= y_offset_within_row * (dim[0] - 1)\n",
    "                    position = 'x'.join([str(n) for n in [n_col, n_row]])\n",
    "                    coordinates[position] = (x, y)\n",
    "                n_col += 1\n",
    "            n_row += 1\n",
    "        self.overlaps = []\n",
    "        return self._normalize_coordinates(coordinates)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _cv_coordinates(self, detector='SIFT', **kwargs):\n",
    "        \"\"\"Uses OpenCV to determine coordinates of tiles in mosaic\n",
    "\n",
    "        Tiles are placed by identifying a well-positioned tile and\n",
    "        building outward. This approach performs poorly for objects\n",
    "        with multiple features of interest separated by featureless\n",
    "        expanses.\n",
    "\n",
    "        Args\n",
    "            detector (str): name of feature-detection algoritm.\n",
    "                Currently, the only acceptable value is SIFT.\n",
    "            kwargs: see :py:func:`~Stitch2D.Mosaic.mosey`\n",
    "                for additional keywords\n",
    "\n",
    "        Returns:\n",
    "            A dict of coordinates specifying the placement of\n",
    "            tiles on the final mosaic\n",
    "        \"\"\"\n",
    "        tiles = {}\n",
    "        overlaps = []\n",
    "        n_row = 0\n",
    "        while n_row < len(self.grid):\n",
    "            row = self.grid[n_row]\n",
    "            n_col = 0\n",
    "            while n_col < len(row):\n",
    "                tile = row[n_col]\n",
    "                pos = (n_col, n_row)\n",
    "                try:\n",
    "                    tiles[tile]\n",
    "                except KeyError:\n",
    "                    tiles[tile] = {\n",
    "                        'position' : pos,\n",
    "                        'offsets' : [],\n",
    "                        'coordinates' : None\n",
    "                    }\n",
    "                if n_col:\n",
    "                    neighbor = row[n_col-1]\n",
    "                    offset = self._cv_match(tile, neighbor, **kwargs)\n",
    "                    #_w = 1280.\n",
    "                    #offset = (-(_w - 19.), 30.), 100, 100\n",
    "                    if offset:\n",
    "                        #input(offset)\n",
    "                        xy, n_total, n_cluster = offset\n",
    "                        nxy = (xy[0]*-1, xy[1]*-1)\n",
    "                        score = self._cv_reliability(n_cluster, n_total)\n",
    "                        tiles[tile]['offsets'].append(['left', xy, score])\n",
    "                        tiles[neighbor]['offsets'].append(['right', nxy,\n",
    "                                                           score])\n",
    "                        if score > 5:\n",
    "                            overlaps.append(self.col_compare(offset, pos,\n",
    "                                                             tile, neighbor))\n",
    "                if n_row:\n",
    "                    neighbor = self.grid[n_row-1][n_col]\n",
    "                    offset = self._cv_match(tile, neighbor, **kwargs)\n",
    "                    if offset:\n",
    "                        #input(offset)\n",
    "                        xy, n_total, n_cluster = offset\n",
    "                        nxy = (xy[0]*-1, xy[1]*-1)\n",
    "                        score = self._cv_reliability(n_cluster, n_total)\n",
    "                        tiles[tile]['offsets'].append(['top', xy, score])\n",
    "                        tiles[neighbor]['offsets'].append(['down', nxy,\n",
    "                                                           score])\n",
    "                        if score > 5:\n",
    "                            overlaps.append(self.row_compare(offset, pos,\n",
    "                                                             tile, neighbor))\n",
    "                n_col += 1\n",
    "            n_row += 1\n",
    "        self.overlaps = overlaps\n",
    "        self._analyze_offsets(tiles)\n",
    "        '''\n",
    "        # Score matches between tiles to find a well-positioned tile\n",
    "        # in the middle 50% of image\n",
    "        root = None\n",
    "        high_score = -1\n",
    "        min_col = 0 * n_col\n",
    "        max_col = n_col - min_col\n",
    "        min_row = 0 * n_row\n",
    "        max_row = n_col - min_row\n",
    "        for tile in sorted(tiles):\n",
    "            n_col, n_row = tiles[tile]['position']\n",
    "            if (min_col < n_col < max_col and min_row < n_row < max_row):\n",
    "                offsets = tiles[tile]['offsets']\n",
    "                try:\n",
    "                    score = sorted(offsets, key=lambda s:s[2]).pop()[2]\n",
    "                except IndexError:\n",
    "                    pass\n",
    "                else:\n",
    "                    #print '{}x{}: {}'.format(n_col, n_row, score)\n",
    "                    if score > high_score:\n",
    "                        root = tile\n",
    "                        high_score = score\n",
    "        '''\n",
    "        islands = {}\n",
    "        for tile in [tile for tile in tiles if tile]:\n",
    "            key = copy(tile)\n",
    "            root = tile\n",
    "            # Place tiles relative to the root tile from above\n",
    "            position = 'x'.join([str(n) for n in tiles[root]['position']])\n",
    "            coordinates = {position : (0,0)}\n",
    "            roots = [position]\n",
    "            while True:\n",
    "                neighbors = []\n",
    "                for root in roots:\n",
    "                    n_col, n_row = [int(n) for n  in root.split('x')]\n",
    "                    tile = tiles[self.grid[n_row][n_col]]\n",
    "                    cprint(('Positioning tiles adjacent to'\n",
    "                           ' {}...').format(os.path.basename(root)),\n",
    "                                            self.verbose)\n",
    "                    offsets = tile['offsets']\n",
    "                    offsets = [offset for offset in offsets if offset[2] >= 5]\n",
    "                    for offset in offsets:\n",
    "                        direction = offset[0]\n",
    "                        dx, dy = offset[1]\n",
    "                        if direction == 'top':\n",
    "                            x, y = n_col, n_row - 1\n",
    "                        elif direction == 'right':\n",
    "                            x, y = n_col+1, n_row\n",
    "                        elif direction == 'down':\n",
    "                            x, y = n_col, n_row + 1\n",
    "                        elif direction == 'left':\n",
    "                            x, y = n_col-1, n_row\n",
    "                        try:\n",
    "                            self.grid[y][x]\n",
    "                        except IndexError:\n",
    "                            pass\n",
    "                        else:\n",
    "                            position = 'x'.join([str(n) for n in [x, y]])\n",
    "                            try:\n",
    "                                coordinates[position]\n",
    "                            except KeyError:\n",
    "                                x, y = coordinates[root]\n",
    "                                coordinates[position] = (x + dx, y + dy)\n",
    "                                neighbors.append(position)\n",
    "                roots = neighbors\n",
    "                if not len(roots):\n",
    "                    break\n",
    "            islands[key] = coordinates\n",
    "        # Identify largest island\n",
    "        n = max([len(islands[key]) for key in islands])\n",
    "        for key in sorted(islands):\n",
    "            if len(islands[key]) == n:\n",
    "                coordinates = islands[key]\n",
    "                break\n",
    "        cprint('{} selected as root ({}/{} tiles represented)'.format(\n",
    "                    os.path.basename(key), n, len(tiles)))\n",
    "        return self._normalize_coordinates(coordinates)\n",
    "\n",
    "\n",
    "    def row_compare(self, xy, tile, fp1, fp2):\n",
    "        im1 = Image.open(fp1)\n",
    "        w, h = im1.size\n",
    "        dx, dy = [abs(int(n)) for n in xy[0]]\n",
    "        x1, y1 = dx, 0\n",
    "        x2, y2 = w, h - dy\n",
    "        box1 = (x1, y1, x2, y2)\n",
    "\n",
    "        im2 = Image.open(fp2)\n",
    "        w, h = im2.size\n",
    "        x1, y1 = 0, dy\n",
    "        x2, y2 = w - dx, h\n",
    "        box2 = (x1, y1, x2, y2)\n",
    "\n",
    "        neighbor = tile[0], tile[1] - 1\n",
    "        #print 'row_compare:', tile, neighbor\n",
    "        #print fp1, self.grid[tile[1]][tile[0]]\n",
    "        #print fp2, self.grid[neighbor[1]][neighbor[0]]\n",
    "        #input()\n",
    "        return ((tile, box1), (neighbor, box2))\n",
    "\n",
    "\n",
    "    def col_compare(self, xy, tile, fp1, fp2):\n",
    "        im1 = Image.open(fp1)\n",
    "        w, h = im1.size\n",
    "        dx, dy = [abs(int(n)) for n in xy[0]]\n",
    "        x1, y1 = 0, 0\n",
    "        x2, y2 = w - dx, h - dy\n",
    "        box1 = (x1, y1, x2, y2)\n",
    "\n",
    "        im2 = Image.open(fp2)\n",
    "        w, h = im2.size\n",
    "        x1, y1 = dx, dy\n",
    "        x2, y2 = w, h\n",
    "        box2 = (x1, y1, x2, y2)\n",
    "\n",
    "        neighbor = tile[0] - 1, tile[1]\n",
    "        #print 'col_compare:', tile, neighbor\n",
    "        #print fp1, self.grid[tile[1]][tile[0]]\n",
    "        #print fp2, self.grid[neighbor[1]][neighbor[0]]\n",
    "        #input()\n",
    "        return ((tile, box1), (neighbor, box2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _cv_match(self, img1, img2, detector='SIFT', **kwargs):\n",
    "        \"\"\"Use OpenCV to match features between two images\n",
    "\n",
    "        Args:\n",
    "            img1 (str): path to image\n",
    "            img2 (str): path to another image\n",
    "            detector: the name of an OpenCV feature detector,\n",
    "                like SIFT or ORB. Currently only SIFT works.\n",
    "            kwargs: see :py:func:`~Stitch2D.Mosaic.mosey`\n",
    "                for additional keywords\n",
    "\n",
    "        Returns:\n",
    "            (x, y), n_clsuter, n_total\n",
    "\n",
    "            Includes average offset, the number of features in the\n",
    "            largest cluster, and the total number of features detected.\n",
    "            Returns None on failure.\n",
    "        \"\"\"\n",
    "        cprint('OpenCV: cv2.xfeatures2d.SIFT_create()', self.verbose)\n",
    "        detector = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "        start_time = datetime.now()\n",
    "\n",
    "        fn1 = os.path.basename(img1)\n",
    "        fn2 = os.path.basename(img2)\n",
    "\n",
    "        # Read descriptors\n",
    "        for fp in (img2, img1):\n",
    "            if not bool(fp):\n",
    "                return None\n",
    "            try:\n",
    "                self.keypoints[fp]\n",
    "            except KeyError:\n",
    "                fn = os.path.basename(fp)\n",
    "                cprint('Getting keypoints for {}'.format(fn), self.normal)\n",
    "                cprint('OpenCV: cv2.imread()', self.verbose)\n",
    "                img = cv2.imread(fp, 0)\n",
    "                if kwargs['scalar'] < 1:\n",
    "                    h, w = [int(n*kwargs['scalar']) for n in img.shape]\n",
    "                    if h and w:\n",
    "                        cprint('OpenCV: cv2.resize()', self.verbose)\n",
    "                        img = cv2.resize(img, (w, h))\n",
    "                if kwargs['equalize_histogram']:\n",
    "                    cprint('OpenCV: cv2.equalizeHist()', self.verbose)\n",
    "                    img = cv2.equalizeHist(img)\n",
    "                cprint('OpenCV: cv2.detectAndCompute()', self.verbose)\n",
    "                self.keypoints[fp] = detector.detectAndCompute(img, None)\n",
    "\n",
    "        kp1, des1 = self.keypoints[img1]\n",
    "        if not (any(kp1) and np.any(des1)):\n",
    "            cprint('No keypoints found in {}'.format(fn1), self.normal)\n",
    "            return None\n",
    "\n",
    "        kp2, des2 = self.keypoints[img2]\n",
    "        if not (any(kp2) and np.any(des2)):\n",
    "            cprint('No keypoints found in {}'.format(fn2), self.normal)\n",
    "            return None\n",
    "\n",
    "        if kwargs['matcher'] == 'flann':\n",
    "            # FLANN-based matching. Segfaults in Ubuntu 14.04, does not\n",
    "            # work with OpenCV 3.1.0 :(.\n",
    "            FLANN_INDEX_KDTREE = 0\n",
    "            index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "            search_params = dict(checks=50)\n",
    "            cprint('OpenCV: cv2.FlannBasedMatcher()', self.verbose)\n",
    "            flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "            try:\n",
    "                cprint('OpenCV: cv2.FlannBasedMatcher.knnMatch()', self.verbose)\n",
    "                matches = flann.knnMatch(des1, des2, k=2)\n",
    "            except cv2.error:\n",
    "                cprint('No matches found in'\n",
    "                       '{1} and {0}'.format(fn1, fn2), self.normal)\n",
    "                return None\n",
    "        else:\n",
    "            # Brute force matching. Slower.\n",
    "            cprint('OpenCV: cv2.BFMatcher()', self.verbose)\n",
    "            bf = cv2.BFMatcher()\n",
    "            try:\n",
    "                cprint('OpenCV: cv2.BFMatcher.knnMatch()', self.verbose)\n",
    "                matches = bf.knnMatch(des1, des2, k=2)\n",
    "            except cv2.error:\n",
    "                cprint('No matches found in'\n",
    "                       '{1} and {0}'.format(fn1, fn2), self.normal)\n",
    "                return None\n",
    "\n",
    "        # Matches consist of DMatch objects, which among other things\n",
    "        # contain coordinates for keypoints in kp1 and kp2. These can\n",
    "        # be used to calculate an average offset between two tiles;\n",
    "        # the average is based on a simple cluster analysis of matches\n",
    "        # detected between the two images.\n",
    "\n",
    "        # Identify good matches using ratio test from Lowe's paper. The\n",
    "        # length test bypasses an error in which some matches returned\n",
    "        # by the detector.knnMatch() function have <k results.\n",
    "        good = []\n",
    "        for m, n in [m for m in matches if len(m)==2]:\n",
    "            if m.distance < kwargs['threshold'] * n.distance:\n",
    "                good.append(m)\n",
    "\n",
    "        fn1 = os.path.basename(img1)\n",
    "        fn2 = os.path.basename(img2)\n",
    "        x = []\n",
    "        y = []\n",
    "\n",
    "        # Identify inliers using homography\n",
    "        if kwargs['homography'] and len(good) >= 5:\n",
    "            src_pts = np.float32([kp1[m.queryIdx].pt\n",
    "                                  for m in good]).reshape(-1,1,2)\n",
    "            dst_pts = np.float32([kp2[m.trainIdx].pt\n",
    "                                  for m in good]).reshape(-1,1,2)\n",
    "\n",
    "            M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "            try:\n",
    "                matchesMask = mask.ravel().tolist()\n",
    "            except AttributeError:\n",
    "                return (0, 0), 0, len(matches)\n",
    "\n",
    "            # Use inlier list to determine offset\n",
    "            i = 0\n",
    "            while i < len(matchesMask):\n",
    "                c1 = good[i].queryIdx\n",
    "                c2 = good[i].trainIdx\n",
    "                x.append((kp1[c1].pt[0] - kp2[c2].pt[0]) / kwargs['scalar'])\n",
    "                y.append((kp1[c1].pt[1] - kp2[c2].pt[1]) / kwargs['scalar'])\n",
    "                i += 1\n",
    "            x_avg = sum(x) / len(x)\n",
    "            y_avg = sum(y) / len(y)\n",
    "\n",
    "            # Return coordinates, total size, and cluster size\n",
    "            n = len(x)\n",
    "            m = n #len(matches)\n",
    "            dt = datetime.now() - start_time\n",
    "            cprint(('Matched {} features in {} and {}'\n",
    "                    ' (t={})').format(n, fn1, fn2, dt), self.normal)\n",
    "            return (x_avg, y_avg), n, m\n",
    "        else:\n",
    "            # Identify inliers using a simple clustering approach\n",
    "            for m in good:\n",
    "                c1 = m.queryIdx\n",
    "                c2 = m.trainIdx\n",
    "                x.append((kp1[c1].pt[0] - kp2[c2].pt[0]) / kwargs['scalar'])\n",
    "                y.append((kp1[c1].pt[1] - kp2[c2].pt[1]) / kwargs['scalar'])\n",
    "            if len(x) and len(y):\n",
    "                groups = cluster(x, 2)\n",
    "                x_max = max([len(group) for group in groups])\n",
    "                group = [group for group in groups if len(group)==x_max][0]\n",
    "                x_avg = sum(group) / len(group)\n",
    "\n",
    "                groups = cluster(y, 2)\n",
    "                y_max = max([len(group) for group in groups])\n",
    "                group = [group for group in groups if len(group)==y_max][0]\n",
    "                y_avg = sum(group) / len(group)\n",
    "\n",
    "                # Return coordinates, total size, and cluster size\n",
    "                n = len(x)\n",
    "                m = min([x_max, y_max])\n",
    "                dt = datetime.now() - start_time\n",
    "                cprint(('Matched {}/{} features in {} and {}'\n",
    "                        ' (t={})').format(m, n, fn1, fn2, dt), self.normal)\n",
    "                return (x_avg, y_avg), n, m\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _cv_reliability(self, n_cluster, n_total):\n",
    "        \"\"\"Assess reliability of offset\n",
    "\n",
    "        Args:\n",
    "            n_cluster (int): size of largest cluster of features\n",
    "            n_total (int): size of list of all features\n",
    "\n",
    "        Returns:\n",
    "            Reliability score, which is just the number of\n",
    "            matches adjusted by frequency. Values above 5\n",
    "            are considered reliable. This is not great.\n",
    "        \"\"\"\n",
    "        # Offset reliability test\n",
    "        #  1. Are there a large number of matches?\n",
    "        #  2. Do most of these matches cluster in one group?\n",
    "        #  Minima: 4/5, 4/6, 5/7, 5/8, 6/9, then >50% for 10+\n",
    "        try:\n",
    "            pct_cluster = n_cluster / float(n_total)\n",
    "        except ZeroDivisionError:\n",
    "            pct_cluster = 0\n",
    "        return n_cluster * pct_cluster\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _analyze_offsets(self, tiles):\n",
    "        \"\"\"Placeholder for future test\"\"\"\n",
    "        for tile in tiles:\n",
    "            tile = tiles[tile]\n",
    "            n_row, n_col = tile['position']\n",
    "            offsets = tile['offsets']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _normalize_coordinates(self, coordinates):\n",
    "        \"\"\"Calibrates calculated coordinates to zero the minimum on each axis\n",
    "\n",
    "        Args:\n",
    "            coordinates (dict): raw coordinates for each tile in mosaic\n",
    "\n",
    "        Returns:\n",
    "            A dict containing the calibrated coordinates for each\n",
    "            tile.\n",
    "        \"\"\"\n",
    "        x_min = min([coordinate[0] for coordinate in coordinates.values()])\n",
    "        x_max = max([coordinate[0] for coordinate in coordinates.values()])\n",
    "        y_min = min([coordinate[1] for coordinate in coordinates.values()])\n",
    "        y_max = max([coordinate[1] for coordinate in coordinates.values()])\n",
    "\n",
    "        # Shift everything so that minimum coordinates are 0,0\n",
    "        for tile in coordinates:\n",
    "            x, y = coordinates[tile]\n",
    "            coordinates[tile] = int(x - x_min), int(y - y_min)\n",
    "\n",
    "        return {'coordinates': coordinates, 'overlaps': self.overlaps}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def mosey(path=None, output='.', param_file='params.json', skip_file=None,\n",
    "          create_jpeg=False, opencv=True, label=None, **kwargs):\n",
    "    \"\"\"Stitches a set of directories using one set of parameters\n",
    "\n",
    "    Use this function to stitch derivatives from a master file\n",
    "    (like NSS element maps) or images collected at the same time\n",
    "    under different light source.\n",
    "\n",
    "    If no list of skipped tiles is provided, mosey will check\n",
    "    for one along the specified path.\n",
    "\n",
    "    Args:\n",
    "        path (str): filepath to either a directory containing tiles\n",
    "            *or* a directory containing one or more directories\n",
    "            containing tiles\n",
    "        param_file (str): filepath to parameters file\n",
    "        skip_file (str): filepath to a list of skipped tiles. If\n",
    "            excluded, the function will search the path for a list.\n",
    "        opencv (bool): specifies whether to use OpenCV. If\n",
    "            OpenCV is not installed, the function will revert\n",
    "            to matching tiles manually.\n",
    "        create_jpeg (bool): specifies whether to create a\n",
    "            half-size JPEG derivative of the final mosaic\n",
    "        label (str): name of the mosaic (typically the sample name)\n",
    "        equalize_histogram (bool): specifies whether to equalize\n",
    "            histogram before matching features (\\*\\*kwarg)\n",
    "        matcher (str): name of feature-matching algoritm (\\*\\*kwarg)\n",
    "        scalar (float): amount to scale imahes before matching\n",
    "            (\\*\\*kwarg)\n",
    "        threshold (float): threshold for Lowe test (\\*\\*kwarg)\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if not path:\n",
    "        path = _select_folder()\n",
    "        kwargs['path'] = path\n",
    "    # Check for tiles. If none found, try the parent directory.\n",
    "    try:\n",
    "        tilesets = [os.path.join(path, dn) for dn in os.listdir(path)\n",
    "                    if os.path.isdir(os.path.join(path, dn))\n",
    "                    and not dn == 'skipped']\n",
    "    except TypeError:\n",
    "        raise Exception('No filepath provided! Exiting')\n",
    "    if not tilesets:\n",
    "        cprint('No subdirectories found in {}. Processing'\n",
    "               ' main directory instead.'.format(path))\n",
    "        tilesets = [path]\n",
    "    for path in copy(tilesets):\n",
    "        if 'bsed' in path or 'ppl' in path:\n",
    "            tilesets.insert(0, tilesets.pop(tilesets.index(path)))\n",
    "    # Check for skipped files. By default, mosey will check all\n",
    "    # subdirectories of the main directory for skipped file list and then\n",
    "    # apply that list to everything processed in the current job. Also,\n",
    "    # element maps can be hit or miss for setting offsets, so we shift\n",
    "    # backscatter images to top of the list if they're available.\n",
    "    if skip_file is None:\n",
    "        skip_files = []\n",
    "        for path in tilesets:\n",
    "            try:\n",
    "                open(os.path.join(path, 'skipped.txt'))\n",
    "            except IOError:\n",
    "                pass\n",
    "            else:\n",
    "                skip_files.append(path)\n",
    "        if len(skip_files) > 1:\n",
    "            cprint('Warning: Multiple skip lists found:\\n ' +\n",
    "                   ' \\n'.join(skip_files))\n",
    "        if len(skip_files):\n",
    "            skip_file = skip_file[0]\n",
    "            cprint('Using list of skipped tiles'\n",
    "                   ' from {}'.format(skip_file))\n",
    "    positions = None\n",
    "    param_file = os.path.join(output, param_file)\n",
    "    for path in tilesets:\n",
    "        cprint('New tileset: {}'.format(os.path.basename(path)))\n",
    "        # Check for element in foldername\n",
    "        mosaic = Mosaic(path, output=output, param_file=param_file,\n",
    "                        skip_file=skip_file, label=label, **kwargs)\n",
    "        if mosaic.grid:\n",
    "            if not positions:\n",
    "                positions = mosaic.prepare_mosaic(param_file, opencv, **kwargs)\n",
    "            mosaic.create_mosaic(positions, create_jpeg=create_jpeg)\n",
    "        else:\n",
    "            print(u'Skipped',path)\n",
    "    # Remove parameters file\n",
    "    try:\n",
    "        os.remove(param_file)\n",
    "    except OSError:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\n"
     ]
    }
   ],
   "source": [
    "# Input Vars\n",
    "odir = \"I:\\Summer 2019\\Capstone\\Frames-DemoTest\"\n",
    "tdir = \"I:\\Summer 2019\\Capstone\\Frames-DemoTest\\demo-5\\demo5-calibrated\"\n",
    "\n",
    "odir = odir.replace(\"\\\\\",\"\\\\\\\\\") # have to double up b.c. escape character\n",
    "tdir = tdir.replace(\"\\\\\",\"\\\\\\\\\") # have to double up b.c. escape character\n",
    "print(odir)\n",
    "print(tdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demo5-calibrated => demo5-calibrated\n",
      "Testing path I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000159.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000160.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000161.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000162.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000163.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000164.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000165.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000166.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000167.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000168.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000169.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000170.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000171.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000172.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000173.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000174.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000175.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000176.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000177.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000178.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000179.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000180.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000181.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000182.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000183.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000184.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000185.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000186.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000187.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000188.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000189.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000190.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000191.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000192.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000193.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000194.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000195.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000196.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000197.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000198.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000199.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000200.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000201.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000202.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000203.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000204.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000205.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000206.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000207.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000208.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000209.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000210.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000211.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000212.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000213.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000214.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000215.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000216.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000217.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000218.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000219.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000220.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000221.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000222.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000223.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000224.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000225.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000226.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000227.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000228.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000229.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000230.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000231.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000232.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000233.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000234.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000235.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000236.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000237.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000238.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000239.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000240.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000241.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000242.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000243.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000244.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000245.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000246.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000247.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000248.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000249.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000250.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000251.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000252.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000253.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000254.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000255.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000256.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000257.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000258.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000259.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000260.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000261.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000262.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000263.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000264.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000265.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000266.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000267.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000268.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000269.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000270.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000271.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000272.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000273.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000274.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000275.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000276.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000277.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000278.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000279.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000280.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000281.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000282.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000283.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000284.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000285.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000286.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000287.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000288.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000289.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000290.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000291.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000292.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000293.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000294.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000295.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000296.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000297.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000298.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000299.jpg\n",
      "I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\demo-5\\\\demo5-calibrated\\output_0000300.jpg\n",
      "The tileset contains 142 tiles\n",
      "Set tileset parameters:\n",
      "Mosaic parameters:\n",
      " Dimensions:     1x142\n",
      " Snake:          None\n",
      " Smooth:         True\n",
      " Blur radius:    0\n",
      " Minimum pixel:  0\n",
      "DEBUG: Populate Tiles Return\n"
     ]
    }
   ],
   "source": [
    "#stitch2d mosaic -threshold=1 --smooth -path \"C:\\Frames-DemoTest\\demo-5\"\n",
    "\n",
    "tiles = Mosaic(path=tdir,num_cols=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using OpenCV to stitch mosaic\n",
      "  Equalize histogram: False\n",
      "  Matcher:            brute-force\n",
      "  Homography:         False\n",
      "  Scalar:             0.5\n",
      "  Threshold:          1\n",
      "Determining offset...\n",
      "Getting keypoints for output_0000159.jpg\n",
      "Getting keypoints for output_0000160.jpg\n",
      "Matched 6/162 features in output_0000160.jpg and output_0000159.jpg\n",
      "  (t=0:00:00.096741)\n",
      "Getting keypoints for output_0000161.jpg\n",
      "Matched 4/39 features in output_0000161.jpg and output_0000160.jpg\n",
      "  (t=0:00:00.044880)\n",
      "Getting keypoints for output_0000162.jpg\n",
      "Matched 5/37 features in output_0000162.jpg and output_0000161.jpg\n",
      "  (t=0:00:00.047872)\n",
      "Getting keypoints for output_0000163.jpg\n",
      "Matched 10/45 features in output_0000163.jpg and output_0000162.jpg\n",
      "  (t=0:00:00.045877)\n",
      "Getting keypoints for output_0000164.jpg\n",
      "Matched 8/126 features in output_0000164.jpg and output_0000163.jpg\n",
      "  (t=0:00:00.049867)\n",
      "Getting keypoints for output_0000165.jpg\n",
      "Matched 27/133 features in output_0000165.jpg and output_0000164.jpg\n",
      "  (t=0:00:00.049867)\n",
      "Getting keypoints for output_0000166.jpg\n",
      "Matched 23/205 features in output_0000166.jpg and output_0000165.jpg\n",
      "  (t=0:00:00.049866)\n",
      "Getting keypoints for output_0000167.jpg\n",
      "Matched 42/209 features in output_0000167.jpg and output_0000166.jpg\n",
      "  (t=0:00:00.050864)\n",
      "Getting keypoints for output_0000168.jpg\n",
      "Matched 56/300 features in output_0000168.jpg and output_0000167.jpg\n",
      "  (t=0:00:00.050864)\n",
      "Getting keypoints for output_0000169.jpg\n",
      "Matched 81/221 features in output_0000169.jpg and output_0000168.jpg\n",
      "  (t=0:00:00.048869)\n",
      "Getting keypoints for output_0000170.jpg\n",
      "Matched 69/239 features in output_0000170.jpg and output_0000169.jpg\n",
      "  (t=0:00:00.048376)\n",
      "Getting keypoints for output_0000171.jpg\n",
      "Matched 59/244 features in output_0000171.jpg and output_0000170.jpg\n",
      "  (t=0:00:00.054854)\n",
      "Getting keypoints for output_0000172.jpg\n",
      "Matched 59/206 features in output_0000172.jpg and output_0000171.jpg\n",
      "  (t=0:00:00.048376)\n",
      "Getting keypoints for output_0000173.jpg\n",
      "Matched 56/176 features in output_0000173.jpg and output_0000172.jpg\n",
      "  (t=0:00:00.048870)\n",
      "Getting keypoints for output_0000174.jpg\n",
      "Matched 66/203 features in output_0000174.jpg and output_0000173.jpg\n",
      "  (t=0:00:00.047871)\n",
      "Getting keypoints for output_0000175.jpg\n",
      "Matched 61/153 features in output_0000175.jpg and output_0000174.jpg\n",
      "  (t=0:00:00.047872)\n",
      "Getting keypoints for output_0000176.jpg\n",
      "Matched 48/185 features in output_0000176.jpg and output_0000175.jpg\n",
      "  (t=0:00:00.047872)\n",
      "Getting keypoints for output_0000177.jpg\n",
      "Matched 45/210 features in output_0000177.jpg and output_0000176.jpg\n",
      "  (t=0:00:00.047872)\n",
      "Getting keypoints for output_0000178.jpg\n",
      "Matched 23/196 features in output_0000178.jpg and output_0000177.jpg\n",
      "  (t=0:00:00.048869)\n",
      "Getting keypoints for output_0000179.jpg\n",
      "Matched 56/174 features in output_0000179.jpg and output_0000178.jpg\n",
      "  (t=0:00:00.048869)\n",
      "Getting keypoints for output_0000180.jpg\n",
      "Matched 48/192 features in output_0000180.jpg and output_0000179.jpg\n",
      "  (t=0:00:00.047873)\n",
      "Getting keypoints for output_0000181.jpg\n",
      "Matched 50/153 features in output_0000181.jpg and output_0000180.jpg\n",
      "  (t=0:00:00.047872)\n",
      "Getting keypoints for output_0000182.jpg\n",
      "Matched 74/220 features in output_0000182.jpg and output_0000181.jpg\n",
      "  (t=0:00:00.047872)\n",
      "Getting keypoints for output_0000183.jpg\n",
      "Matched 97/242 features in output_0000183.jpg and output_0000182.jpg\n",
      "  (t=0:00:00.051861)\n",
      "Getting keypoints for output_0000184.jpg\n",
      "Matched 139/289 features in output_0000184.jpg and output_0000183.jpg\n",
      "  (t=0:00:00.048870)\n",
      "Getting keypoints for output_0000185.jpg\n",
      "Matched 134/298 features in output_0000185.jpg and output_0000184.jpg\n",
      "  (t=0:00:00.049867)\n",
      "Getting keypoints for output_0000186.jpg\n",
      "Matched 137/370 features in output_0000186.jpg and output_0000185.jpg\n",
      "  (t=0:00:00.050864)\n",
      "Getting keypoints for output_0000187.jpg\n",
      "Matched 135/280 features in output_0000187.jpg and output_0000186.jpg\n",
      "  (t=0:00:00.048868)\n",
      "Getting keypoints for output_0000188.jpg\n",
      "Matched 136/298 features in output_0000188.jpg and output_0000187.jpg\n",
      "  (t=0:00:00.048870)\n",
      "Getting keypoints for output_0000189.jpg\n",
      "Matched 109/300 features in output_0000189.jpg and output_0000188.jpg\n",
      "  (t=0:00:00.048870)\n",
      "Getting keypoints for output_0000190.jpg\n",
      "Matched 131/354 features in output_0000190.jpg and output_0000189.jpg\n",
      "  (t=0:00:00.049867)\n",
      "Getting keypoints for output_0000191.jpg\n",
      "Matched 122/252 features in output_0000191.jpg and output_0000190.jpg\n",
      "  (t=0:00:00.049375)\n",
      "Getting keypoints for output_0000192.jpg\n",
      "Matched 137/265 features in output_0000192.jpg and output_0000191.jpg\n",
      "  (t=0:00:00.053856)\n",
      "Getting keypoints for output_0000193.jpg\n",
      "Matched 122/281 features in output_0000193.jpg and output_0000192.jpg\n",
      "  (t=0:00:00.052859)\n",
      "Getting keypoints for output_0000194.jpg\n",
      "Matched 124/345 features in output_0000194.jpg and output_0000193.jpg\n",
      "  (t=0:00:00.052859)\n",
      "Getting keypoints for output_0000195.jpg\n",
      "Matched 104/275 features in output_0000195.jpg and output_0000194.jpg\n",
      "  (t=0:00:00.051861)\n",
      "Getting keypoints for output_0000196.jpg\n",
      "Matched 138/385 features in output_0000196.jpg and output_0000195.jpg\n",
      "  (t=0:00:00.051861)\n",
      "Getting keypoints for output_0000197.jpg\n",
      "Matched 122/229 features in output_0000197.jpg and output_0000196.jpg\n",
      "  (t=0:00:00.048869)\n",
      "Getting keypoints for output_0000198.jpg\n",
      "Matched 113/273 features in output_0000198.jpg and output_0000197.jpg\n",
      "  (t=0:00:00.049866)\n",
      "Getting keypoints for output_0000199.jpg\n",
      "Matched 81/243 features in output_0000199.jpg and output_0000198.jpg\n",
      "  (t=0:00:00.050863)\n",
      "Getting keypoints for output_0000200.jpg\n",
      "Matched 95/251 features in output_0000200.jpg and output_0000199.jpg\n",
      "  (t=0:00:00.054365)\n",
      "Getting keypoints for output_0000201.jpg\n",
      "Matched 118/255 features in output_0000201.jpg and output_0000200.jpg\n",
      "  (t=0:00:00.056849)\n",
      "Getting keypoints for output_0000202.jpg\n",
      "Matched 131/269 features in output_0000202.jpg and output_0000201.jpg\n",
      "  (t=0:00:00.053362)\n",
      "Getting keypoints for output_0000203.jpg\n",
      "Matched 131/249 features in output_0000203.jpg and output_0000202.jpg\n",
      "  (t=0:00:00.050863)\n",
      "Getting keypoints for output_0000204.jpg\n",
      "Matched 126/238 features in output_0000204.jpg and output_0000203.jpg\n",
      "  (t=0:00:00.050371)\n",
      "Getting keypoints for output_0000205.jpg\n",
      "Matched 116/249 features in output_0000205.jpg and output_0000204.jpg\n",
      "  (t=0:00:00.047872)\n",
      "Getting keypoints for output_0000206.jpg\n",
      "Matched 136/272 features in output_0000206.jpg and output_0000205.jpg\n",
      "  (t=0:00:00.053380)\n",
      "Getting keypoints for output_0000207.jpg\n",
      "Matched 119/280 features in output_0000207.jpg and output_0000206.jpg\n",
      "  (t=0:00:00.052859)\n",
      "Getting keypoints for output_0000208.jpg\n",
      "Matched 131/311 features in output_0000208.jpg and output_0000207.jpg\n",
      "  (t=0:00:00.051861)\n",
      "Getting keypoints for output_0000209.jpg\n",
      "Matched 169/390 features in output_0000209.jpg and output_0000208.jpg\n",
      "  (t=0:00:00.054853)\n",
      "Getting keypoints for output_0000210.jpg\n",
      "Matched 183/355 features in output_0000210.jpg and output_0000209.jpg\n",
      "  (t=0:00:00.052858)\n",
      "Getting keypoints for output_0000211.jpg\n",
      "Matched 165/351 features in output_0000211.jpg and output_0000210.jpg\n",
      "  (t=0:00:00.051862)\n",
      "Getting keypoints for output_0000212.jpg\n",
      "Matched 179/363 features in output_0000212.jpg and output_0000211.jpg\n",
      "  (t=0:00:00.051861)\n",
      "Getting keypoints for output_0000213.jpg\n",
      "Matched 101/369 features in output_0000213.jpg and output_0000212.jpg\n",
      "  (t=0:00:00.052859)\n",
      "Getting keypoints for output_0000214.jpg\n",
      "Matched 97/361 features in output_0000214.jpg and output_0000213.jpg\n",
      "  (t=0:00:00.053856)\n",
      "Getting keypoints for output_0000215.jpg\n",
      "Matched 87/323 features in output_0000215.jpg and output_0000214.jpg\n",
      "  (t=0:00:00.052859)\n",
      "Getting keypoints for output_0000216.jpg\n",
      "Matched 105/428 features in output_0000216.jpg and output_0000215.jpg\n",
      "  (t=0:00:00.053856)\n",
      "Getting keypoints for output_0000217.jpg\n",
      "Matched 112/380 features in output_0000217.jpg and output_0000216.jpg\n",
      "  (t=0:00:00.053856)\n",
      "Getting keypoints for output_0000218.jpg\n",
      "Matched 112/409 features in output_0000218.jpg and output_0000217.jpg\n",
      "  (t=0:00:00.051861)\n",
      "Getting keypoints for output_0000219.jpg\n",
      "Matched 123/466 features in output_0000219.jpg and output_0000218.jpg\n",
      "  (t=0:00:00.051862)\n",
      "Getting keypoints for output_0000220.jpg\n",
      "Matched 101/430 features in output_0000220.jpg and output_0000219.jpg\n",
      "  (t=0:00:00.056848)\n",
      "Getting keypoints for output_0000221.jpg\n",
      "Matched 102/467 features in output_0000221.jpg and output_0000220.jpg\n",
      "  (t=0:00:00.056848)\n",
      "Getting keypoints for output_0000222.jpg\n",
      "Matched 196/448 features in output_0000222.jpg and output_0000221.jpg\n",
      "  (t=0:00:00.056847)\n",
      "Getting keypoints for output_0000223.jpg\n",
      "Matched 197/434 features in output_0000223.jpg and output_0000222.jpg\n",
      "  (t=0:00:00.055358)\n",
      "Getting keypoints for output_0000224.jpg\n",
      "Matched 207/451 features in output_0000224.jpg and output_0000223.jpg\n",
      "  (t=0:00:00.054853)\n",
      "Getting keypoints for output_0000225.jpg\n",
      "Matched 115/442 features in output_0000225.jpg and output_0000224.jpg\n",
      "  (t=0:00:00.052858)\n",
      "Getting keypoints for output_0000226.jpg\n",
      "Matched 90/325 features in output_0000226.jpg and output_0000225.jpg\n",
      "  (t=0:00:00.051861)\n",
      "Getting keypoints for output_0000227.jpg\n",
      "Matched 54/306 features in output_0000227.jpg and output_0000226.jpg\n",
      "  (t=0:00:00.048870)\n",
      "Getting keypoints for output_0000228.jpg\n",
      "Matched 104/251 features in output_0000228.jpg and output_0000227.jpg\n",
      "  (t=0:00:00.050864)\n",
      "Getting keypoints for output_0000229.jpg\n",
      "Matched 64/218 features in output_0000229.jpg and output_0000228.jpg\n",
      "  (t=0:00:00.053856)\n",
      "Getting keypoints for output_0000230.jpg\n",
      "Matched 75/198 features in output_0000230.jpg and output_0000229.jpg\n",
      "  (t=0:00:00.051861)\n",
      "Getting keypoints for output_0000231.jpg\n",
      "Matched 56/159 features in output_0000231.jpg and output_0000230.jpg\n",
      "  (t=0:00:00.053856)\n",
      "Getting keypoints for output_0000232.jpg\n",
      "Matched 61/167 features in output_0000232.jpg and output_0000231.jpg\n",
      "  (t=0:00:00.050373)\n",
      "Getting keypoints for output_0000233.jpg\n",
      "Matched 70/163 features in output_0000233.jpg and output_0000232.jpg\n",
      "  (t=0:00:00.047872)\n",
      "Getting keypoints for output_0000234.jpg\n",
      "Matched 80/180 features in output_0000234.jpg and output_0000233.jpg\n",
      "  (t=0:00:00.048376)\n",
      "Getting keypoints for output_0000235.jpg\n",
      "Matched 83/207 features in output_0000235.jpg and output_0000234.jpg\n",
      "  (t=0:00:00.047872)\n",
      "Getting keypoints for output_0000236.jpg\n",
      "Matched 92/203 features in output_0000236.jpg and output_0000235.jpg\n",
      "  (t=0:00:00.049373)\n",
      "Getting keypoints for output_0000237.jpg\n",
      "Matched 103/205 features in output_0000237.jpg and output_0000236.jpg\n",
      "  (t=0:00:00.047872)\n",
      "Getting keypoints for output_0000238.jpg\n",
      "Matched 72/213 features in output_0000238.jpg and output_0000237.jpg\n",
      "  (t=0:00:00.049374)\n",
      "Getting keypoints for output_0000239.jpg\n",
      "Matched 85/226 features in output_0000239.jpg and output_0000238.jpg\n",
      "  (t=0:00:00.053856)\n",
      "Getting keypoints for output_0000240.jpg\n",
      "Matched 74/298 features in output_0000240.jpg and output_0000239.jpg\n",
      "  (t=0:00:00.051862)\n",
      "Getting keypoints for output_0000241.jpg\n",
      "Matched 42/240 features in output_0000241.jpg and output_0000240.jpg\n",
      "  (t=0:00:00.049866)\n",
      "Getting keypoints for output_0000242.jpg\n",
      "Matched 104/297 features in output_0000242.jpg and output_0000241.jpg\n",
      "  (t=0:00:00.053849)\n",
      "Getting keypoints for output_0000243.jpg\n",
      "Matched 65/205 features in output_0000243.jpg and output_0000242.jpg\n",
      "  (t=0:00:00.052859)\n",
      "Getting keypoints for output_0000244.jpg\n",
      "Matched 36/168 features in output_0000244.jpg and output_0000243.jpg\n",
      "  (t=0:00:00.053856)\n",
      "Getting keypoints for output_0000245.jpg\n",
      "Matched 47/328 features in output_0000245.jpg and output_0000244.jpg\n",
      "  (t=0:00:00.052859)\n",
      "Getting keypoints for output_0000246.jpg\n",
      "Matched 48/370 features in output_0000246.jpg and output_0000245.jpg\n",
      "  (t=0:00:00.054853)\n",
      "Getting keypoints for output_0000247.jpg\n",
      "Matched 101/335 features in output_0000247.jpg and output_0000246.jpg\n",
      "  (t=0:00:00.049867)\n",
      "Getting keypoints for output_0000248.jpg\n",
      "Matched 73/346 features in output_0000248.jpg and output_0000247.jpg\n",
      "  (t=0:00:00.049867)\n",
      "Getting keypoints for output_0000249.jpg\n",
      "Matched 135/382 features in output_0000249.jpg and output_0000248.jpg\n",
      "  (t=0:00:00.050864)\n",
      "Getting keypoints for output_0000250.jpg\n",
      "Matched 102/407 features in output_0000250.jpg and output_0000249.jpg\n",
      "  (t=0:00:00.051861)\n",
      "Getting keypoints for output_0000251.jpg\n",
      "Matched 87/392 features in output_0000251.jpg and output_0000250.jpg\n",
      "  (t=0:00:00.051861)\n",
      "Getting keypoints for output_0000252.jpg\n",
      "Matched 166/488 features in output_0000252.jpg and output_0000251.jpg\n",
      "  (t=0:00:00.050864)\n",
      "Getting keypoints for output_0000253.jpg\n",
      "Matched 192/444 features in output_0000253.jpg and output_0000252.jpg\n",
      "  (t=0:00:00.051861)\n",
      "Getting keypoints for output_0000254.jpg\n",
      "Matched 132/447 features in output_0000254.jpg and output_0000253.jpg\n",
      "  (t=0:00:00.054853)\n",
      "Getting keypoints for output_0000255.jpg\n",
      "Matched 224/539 features in output_0000255.jpg and output_0000254.jpg\n",
      "  (t=0:00:00.053856)\n",
      "Getting keypoints for output_0000256.jpg\n",
      "Matched 68/326 features in output_0000256.jpg and output_0000255.jpg\n",
      "  (t=0:00:00.049859)\n",
      "Getting keypoints for output_0000257.jpg\n",
      "Matched 70/336 features in output_0000257.jpg and output_0000256.jpg\n",
      "  (t=0:00:00.050864)\n",
      "Getting keypoints for output_0000258.jpg\n",
      "Matched 85/362 features in output_0000258.jpg and output_0000257.jpg\n",
      "  (t=0:00:00.051862)\n",
      "Getting keypoints for output_0000259.jpg\n",
      "Matched 119/354 features in output_0000259.jpg and output_0000258.jpg\n",
      "  (t=0:00:00.050864)\n",
      "Getting keypoints for output_0000260.jpg\n",
      "Matched 139/303 features in output_0000260.jpg and output_0000259.jpg\n",
      "  (t=0:00:00.048869)\n",
      "Getting keypoints for output_0000261.jpg\n",
      "Matched 83/241 features in output_0000261.jpg and output_0000260.jpg\n",
      "  (t=0:00:00.049867)\n",
      "Getting keypoints for output_0000262.jpg\n",
      "Matched 82/261 features in output_0000262.jpg and output_0000261.jpg\n",
      "  (t=0:00:00.049867)\n",
      "Getting keypoints for output_0000263.jpg\n",
      "Matched 78/255 features in output_0000263.jpg and output_0000262.jpg\n",
      "  (t=0:00:00.053856)\n",
      "Getting keypoints for output_0000264.jpg\n",
      "Matched 63/229 features in output_0000264.jpg and output_0000263.jpg\n",
      "  (t=0:00:00.051861)\n",
      "Getting keypoints for output_0000265.jpg\n",
      "Matched 98/235 features in output_0000265.jpg and output_0000264.jpg\n",
      "  (t=0:00:00.051369)\n",
      "Getting keypoints for output_0000266.jpg\n",
      "Matched 86/231 features in output_0000266.jpg and output_0000265.jpg\n",
      "  (t=0:00:00.051861)\n",
      "Getting keypoints for output_0000267.jpg\n",
      "Matched 64/226 features in output_0000267.jpg and output_0000266.jpg\n",
      "  (t=0:00:00.051367)\n",
      "Getting keypoints for output_0000268.jpg\n",
      "Matched 31/172 features in output_0000268.jpg and output_0000267.jpg\n",
      "  (t=0:00:00.047872)\n",
      "Getting keypoints for output_0000269.jpg\n",
      "Matched 45/196 features in output_0000269.jpg and output_0000268.jpg\n",
      "  (t=0:00:00.048376)\n",
      "Getting keypoints for output_0000270.jpg\n",
      "Matched 88/200 features in output_0000270.jpg and output_0000269.jpg\n",
      "  (t=0:00:00.047872)\n",
      "Getting keypoints for output_0000271.jpg\n",
      "Matched 49/173 features in output_0000271.jpg and output_0000270.jpg\n",
      "  (t=0:00:00.053363)\n",
      "Getting keypoints for output_0000272.jpg\n",
      "Matched 72/212 features in output_0000272.jpg and output_0000271.jpg\n",
      "  (t=0:00:00.050864)\n",
      "Getting keypoints for output_0000273.jpg\n",
      "Matched 60/209 features in output_0000273.jpg and output_0000272.jpg\n",
      "  (t=0:00:00.050865)\n",
      "Getting keypoints for output_0000274.jpg\n",
      "Matched 55/217 features in output_0000274.jpg and output_0000273.jpg\n",
      "  (t=0:00:00.050863)\n",
      "Getting keypoints for output_0000275.jpg\n",
      "Matched 118/331 features in output_0000275.jpg and output_0000274.jpg\n",
      "  (t=0:00:00.053857)\n",
      "Getting keypoints for output_0000276.jpg\n",
      "Matched 108/320 features in output_0000276.jpg and output_0000275.jpg\n",
      "  (t=0:00:00.050863)\n",
      "Getting keypoints for output_0000277.jpg\n",
      "Matched 160/358 features in output_0000277.jpg and output_0000276.jpg\n",
      "  (t=0:00:00.049866)\n",
      "Getting keypoints for output_0000278.jpg\n",
      "Matched 201/418 features in output_0000278.jpg and output_0000277.jpg\n",
      "  (t=0:00:00.051862)\n",
      "Getting keypoints for output_0000279.jpg\n",
      "Matched 208/407 features in output_0000279.jpg and output_0000278.jpg\n",
      "  (t=0:00:00.052858)\n",
      "Getting keypoints for output_0000280.jpg\n",
      "Matched 222/447 features in output_0000280.jpg and output_0000279.jpg\n",
      "  (t=0:00:00.052858)\n",
      "Getting keypoints for output_0000281.jpg\n",
      "Matched 193/451 features in output_0000281.jpg and output_0000280.jpg\n",
      "  (t=0:00:00.054853)\n",
      "Getting keypoints for output_0000282.jpg\n",
      "Matched 279/531 features in output_0000282.jpg and output_0000281.jpg\n",
      "  (t=0:00:00.055851)\n",
      "Getting keypoints for output_0000283.jpg\n",
      "Matched 267/522 features in output_0000283.jpg and output_0000282.jpg\n",
      "  (t=0:00:00.056848)\n",
      "Getting keypoints for output_0000284.jpg\n",
      "Matched 253/544 features in output_0000284.jpg and output_0000283.jpg\n",
      "  (t=0:00:00.052858)\n",
      "Getting keypoints for output_0000285.jpg\n",
      "Matched 219/489 features in output_0000285.jpg and output_0000284.jpg\n",
      "  (t=0:00:00.052859)\n",
      "Getting keypoints for output_0000286.jpg\n",
      "Matched 233/438 features in output_0000286.jpg and output_0000285.jpg\n",
      "  (t=0:00:00.054853)\n",
      "Getting keypoints for output_0000287.jpg\n",
      "Matched 222/531 features in output_0000287.jpg and output_0000286.jpg\n",
      "  (t=0:00:00.057845)\n",
      "Getting keypoints for output_0000288.jpg\n",
      "Matched 229/530 features in output_0000288.jpg and output_0000287.jpg\n",
      "  (t=0:00:00.056356)\n",
      "Getting keypoints for output_0000289.jpg\n",
      "Matched 244/573 features in output_0000289.jpg and output_0000288.jpg\n",
      "  (t=0:00:00.057845)\n",
      "Getting keypoints for output_0000290.jpg\n",
      "Matched 175/488 features in output_0000290.jpg and output_0000289.jpg\n",
      "  (t=0:00:00.057845)\n",
      "Getting keypoints for output_0000291.jpg\n",
      "Matched 227/554 features in output_0000291.jpg and output_0000290.jpg\n",
      "  (t=0:00:00.052859)\n",
      "Getting keypoints for output_0000292.jpg\n",
      "Matched 255/514 features in output_0000292.jpg and output_0000291.jpg\n",
      "  (t=0:00:00.053856)\n",
      "Getting keypoints for output_0000293.jpg\n",
      "Matched 276/685 features in output_0000293.jpg and output_0000292.jpg\n",
      "  (t=0:00:00.059840)\n",
      "Getting keypoints for output_0000294.jpg\n",
      "Matched 247/590 features in output_0000294.jpg and output_0000293.jpg\n",
      "  (t=0:00:00.058843)\n",
      "Getting keypoints for output_0000295.jpg\n",
      "Matched 273/649 features in output_0000295.jpg and output_0000294.jpg\n",
      "  (t=0:00:00.057845)\n",
      "Getting keypoints for output_0000296.jpg\n",
      "Matched 335/592 features in output_0000296.jpg and output_0000295.jpg\n",
      "  (t=0:00:00.056847)\n",
      "Getting keypoints for output_0000297.jpg\n",
      "Matched 269/544 features in output_0000297.jpg and output_0000296.jpg\n",
      "  (t=0:00:00.057360)\n",
      "Getting keypoints for output_0000298.jpg\n",
      "Matched 291/556 features in output_0000298.jpg and output_0000297.jpg\n",
      "  (t=0:00:00.056351)\n",
      "Getting keypoints for output_0000299.jpg\n",
      "Matched 261/532 features in output_0000299.jpg and output_0000298.jpg\n",
      "  (t=0:00:00.054848)\n",
      "Getting keypoints for output_0000300.jpg\n",
      "Matched 215/573 features in output_0000300.jpg and output_0000299.jpg\n",
      "  (t=0:00:00.056354)\n",
      "output_0000178.jpg selected as root (123/142 tiles represented)\n",
      "Debug: params.json\n"
     ]
    }
   ],
   "source": [
    "posdata = Mosaic.prepare_mosaic(self=tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mosaic will be 2,128 by 4,510 pixels\n",
      "Stitching mosaic...\n",
      "Saving as JPEG...\n",
      "Mosaic complete! (t=0:00:08.822080)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mosaic.create_mosaic(self=tiles,opath=odir,posdata=posdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
