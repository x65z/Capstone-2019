{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternate image stitching Attempt - Zack H\n",
    "# Accounts for camera shake/wobble, extremely intensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "class Image_Stitching():\n",
    "    def __init__(self) :\n",
    "        self.ratio=0.85\n",
    "        self.min_match=10\n",
    "        self.sift=cv2.xfeatures2d.SIFT_create()\n",
    "        self.smoothing_window_size=800\n",
    "\n",
    "    def registration(self,img1,img2):\n",
    "        kp1, des1 = self.sift.detectAndCompute(img1, None)\n",
    "        kp2, des2 = self.sift.detectAndCompute(img2, None)\n",
    "        matcher = cv2.BFMatcher()\n",
    "        raw_matches = matcher.knnMatch(des1, des2, k=2)\n",
    "        good_points = []\n",
    "        good_matches=[]\n",
    "        for m1, m2 in raw_matches:\n",
    "            if m1.distance < self.ratio * m2.distance:\n",
    "                good_points.append((m1.trainIdx, m1.queryIdx))\n",
    "                good_matches.append([m1])\n",
    "        img3 = cv2.drawMatchesKnn(img1, kp1, img2, kp2, good_matches, None, flags=2)\n",
    "        cv2.imwrite('matching.jpg', img3)\n",
    "        if len(good_points) > self.min_match:\n",
    "            image1_kp = np.float32(\n",
    "                [kp1[i].pt for (_, i) in good_points])\n",
    "            image2_kp = np.float32(\n",
    "                [kp2[i].pt for (i, _) in good_points])\n",
    "            H, status = cv2.findHomography(image2_kp, image1_kp, cv2.RANSAC,5.0)\n",
    "        return H\n",
    "    \n",
    "    def comb_img(self,img1, img2):\n",
    "        x = 0\n",
    "        y = 0\n",
    "        newimg = img1\n",
    "        while x < img1.shape[0]:\n",
    "            while y < img1.shape[1]:\n",
    "                #print(str(img1[x,y]),\" v \",str(img1[x,y]))\n",
    "                if str(img1[x,y]) == '[0 0 0]':\n",
    "                    #print(str(img2[x,y]))\n",
    "                    if str(img2[x,y]) != '[0 0 0]':\n",
    "                        print(str(img2[x,y]))\n",
    "                        newimg[x,y] = img2[x,y]\n",
    "                y += 1\n",
    "            x += 1\n",
    "        return newimg\n",
    "\n",
    "    def mask_img(self,img1,img2):\n",
    "        mat1 = np.zeros((img1.shape[0], img1.shape[1], 1))\n",
    "        mat2 = np.zeros((img2.shape[0], img2.shape[1], 1))\n",
    "        \n",
    "        for i in range(0, img1.shape[0]-1):\n",
    "            for j in range(0, img1.shape[1]-1):\n",
    "                if max(img1[i,j]) > 0:\n",
    "                    mat1[i,j] = 1\n",
    "        for i in range(0, img2.shape[0]-1):\n",
    "            for j in range(0, img2.shape[1]-1):\n",
    "                if (max(img2[i,j]) > 0): \n",
    "                    mat2[i,j] = 1   \n",
    "        mask = np.logical_and(mat1, mat2)        \n",
    "        return mask\n",
    "    \n",
    "    def blending(self,img1,img2):\n",
    "#         H = self.registration(img1,img2)\n",
    "#         print(\"\\nH:\\n\",H)\n",
    "        \n",
    "        height_panorama = img2.shape[0]*5\n",
    "        width_panorama = img2.shape[1]*5\n",
    "        ch = int(height_panorama/2) #center height + width\n",
    "        cw = int(width_panorama/2)\n",
    "\n",
    "        panorama1 = np.zeros((height_panorama, width_panorama, 3))\n",
    "        panorama2 = np.zeros((height_panorama, width_panorama, 3))\n",
    "        \n",
    "        off2h = 0\n",
    "        off2w = 0\n",
    "        off1h = 0\n",
    "        off1w = 0\n",
    "        \n",
    "        #fix rounding error when centering image\n",
    "        if img2.shape[0] % 2 != 0:\n",
    "            off2h = 1\n",
    "        if img2.shape[1] % 2 != 0:\n",
    "            off2w = 1\n",
    "        if img1.shape[0] % 2 != 0:\n",
    "            off1h = 1\n",
    "        if img1.shape[1] % 2 != 0:\n",
    "            off1w = 1        \n",
    "        \n",
    "        panorama1[ch-int(img2.shape[0]/2):ch+int(img2.shape[0]/2)+off2h, cw-int(img2.shape[1]/2):cw+int(img2.shape[1]/2)+off2w, :] = img2\n",
    "        panorama2[ch-int(img1.shape[0]/2):ch+int(img1.shape[0]/2)+off1h, cw-int(img1.shape[1]/2):cw+int(img1.shape[1]/2)+off1w, :] = img1 #center images in panorama\n",
    "        \n",
    "        panorama1 = (panorama1).astype(np.uint8)\n",
    "        panorama2 = (panorama2).astype(np.uint8)\n",
    "        \n",
    "        H = self.registration(panorama1,panorama2)\n",
    "        \n",
    "        panorama2 = cv2.warpPerspective(panorama2, H, (width_panorama, height_panorama))\n",
    "        \n",
    "        rows, cols = np.where(img1[:, :, 0] != 0)\n",
    "        min_row, max_row = min(rows), max(rows) + 1\n",
    "        min_col, max_col = min(cols), max(cols) + 1        \n",
    "        dim1 = [max_row-min_row, max_col-min_col]\n",
    "        \n",
    "        rows, cols = np.where(panorama2[:, :, 0] != 0)\n",
    "        min_row, max_row = min(rows), max(rows) + 1\n",
    "        min_col, max_col = min(cols), max(cols) + 1        \n",
    "        dim2 = [max_row-min_row, max_col-min_col]\n",
    "        \n",
    "        print(\"Width:\",dim1[1],\"v\",dim2[1],\", Height:\",dim1[0],\" v \",dim2[0])\n",
    "        \n",
    "        if (dim2[0] > 3*dim1[0]) or (dim2[1] > 3*dim1[1]) or (dim2[0] < 0.4*dim1[0]) or (dim2[1] < 0.4*dim1[1]):\n",
    "            print(\"> WARNING: New image too distorted, discarding.\") #only allow up to 10% distortion of image or discard\n",
    "            return(img2)\n",
    "        \n",
    "        #res = cv2.bitwise_and(img,img,mask = mask)\n",
    "        \n",
    "        #img1 /= img1.max()/255.0\n",
    "        panorama1 = (panorama1).astype(np.uint8)\n",
    "        panorama2 = (panorama2).astype(np.uint8)\n",
    "        \n",
    "#         print(\"\\n-------------------------\\nPan1:\\n\")\n",
    "#         plt.imshow(panorama1); \n",
    "#         plt.show() \n",
    "#         print(panorama1.max())\n",
    "#         print(\"Pan2:\\n\")\n",
    "#         plt.imshow(panorama2); \n",
    "#         plt.show() \n",
    "#         print(panorama2.max())\n",
    "        \n",
    "        mask = self.mask_img(panorama1, panorama2)\n",
    "        panorama2 = panorama2*np.invert(mask)\n",
    "        #panorama1 = panorama1*mask\n",
    "        \n",
    "        #result = self.comb_img(panorama1,panorama2)\n",
    "        result = panorama1+panorama2\n",
    "        \n",
    "#         print(\"res:\\n\")\n",
    "#         plt.imshow(result); \n",
    "#         plt.show() \n",
    "#         print(result.max())\n",
    "        \n",
    "        rows, cols = np.where(result[:, :, 0] != 0)\n",
    "        min_row, max_row = min(rows), max(rows) + 1\n",
    "        min_col, max_col = min(cols), max(cols) + 1\n",
    "        final_result = result[min_row:max_row, min_col:max_col, :]\n",
    "        return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vars\n",
    "#wdir = \"F:\\\\frames\\\\transformed\\\\conv\"\n",
    "wdir = \"I:\\\\Summer 2019\\\\Capstone\\\\Frames-DemoTest\\\\2b\\\\calibrated\"\n",
    "odir = wdir + \"\\\\stitched\\\\\"\n",
    "ext = \".jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "output_0000274.jpg\n",
      "output_0000275.jpg\n",
      "Width: 1792 v 1757 , Height: 862  v  837\n",
      "output_0000276.jpg\n",
      "Width: 1792 v 1544 , Height: 862  v  944\n",
      "output_0000277.jpg\n",
      "Width: 1792 v 1501 , Height: 862  v  610\n",
      "output_0000278.jpg\n",
      "Width: 1792 v 9120 , Height: 862  v  3829\n",
      "> WARNING: New image too distorted, discarding.\n",
      "output_0000279.jpg\n",
      "Width: 1792 v 3169 , Height: 862  v  1154\n",
      "output_0000280.jpg\n",
      "Width: 1792 v 15845 , Height: 862  v  6660\n",
      "> WARNING: New image too distorted, discarding.\n",
      "output_0000281.jpg\n",
      "Width: 1792 v 15845 , Height: 862  v  6660\n",
      "> WARNING: New image too distorted, discarding.\n",
      "output_0000282.jpg\n",
      "Width: 1792 v 15845 , Height: 862  v  6660\n",
      "> WARNING: New image too distorted, discarding.\n",
      "output_0000283.jpg\n",
      "Width: 1792 v 15845 , Height: 862  v  6660\n",
      "> WARNING: New image too distorted, discarding.\n",
      "output_0000284.jpg\n",
      "Width: 1792 v 15845 , Height: 862  v  6660\n",
      "> WARNING: New image too distorted, discarding.\n",
      "output_0000285.jpg\n",
      "Width: 1792 v 12746 , Height: 862  v  6660\n",
      "> WARNING: New image too distorted, discarding.\n",
      "output_0000286.jpg\n",
      "Width: 1792 v 15845 , Height: 862  v  6660\n",
      "> WARNING: New image too distorted, discarding.\n",
      "output_0000287.jpg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-fff9826e326b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mimg2\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mimg1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage_Stitching\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblending\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[1;31m#img1 /= img1.max()/255.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m#img1 = (img1).astype(np.uint8)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-47-1c98c02404d4>\u001b[0m in \u001b[0;36mblending\u001b[1;34m(self, img1, img2)\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[0mdim1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmax_row\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mmin_row\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_col\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mmin_col\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpanorama2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m         \u001b[0mmin_row\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_row\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[0mmin_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Main, loops over bitmaps and stitches\n",
    "\n",
    "img1 = None\n",
    "img2 = None\n",
    "\n",
    "if odir and not os.path.isdir(odir):\n",
    "    os.mkdir(odir)\n",
    "\n",
    "directory = os.fsencode(wdir)\n",
    "\n",
    "print(\"Processing...\")\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    print(filename)\n",
    "    if filename.endswith(ext):        \n",
    "        img2 = img1\n",
    "        img1 = cv2.imread(wdir + \"\\\\\"+ filename)\n",
    "        #print(\"img1\\n\",img1)\n",
    "        #print(\"img2\\n\",img2)\n",
    "        if img1 is None:\n",
    "            print(\"> WARNING, image empty.\")\n",
    "            continue\n",
    "        if img2 is None:\n",
    "            continue\n",
    "        img1 = Image_Stitching().blending(img1,img2)\n",
    "        #img1 /= img1.max()/255.0\n",
    "        #img1 = (img1).astype(np.uint8)\n",
    "        cv2.imwrite(odir + \"stitched-\"+filename, img1)\n",
    "        #plt.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)); #show color flipped image\n",
    "        #plt.show()  \n",
    "    \n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str(img1[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img1); \n",
    "plt.show() \n",
    "plt.imshow(img2); \n",
    "plt.show() \n",
    "img1.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"img1\\n\",img1)\n",
    "# print(\"img2\\n\",img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COLOR TEST\n",
    "img1 = [[0]]\n",
    "img1[0][0] = [0,0,255] \n",
    "plt.imshow(img1); \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = np.where(img2[:, :, 0] != 0)\n",
    "        min_row, max_row = min(rows), max(rows) + 1\n",
    "        min_col, max_col = min(cols), max(cols) + 1   \n",
    "        leftcorner = np.where(img2[:,mincol,0] != 0)\n",
    "\n",
    "plt.imshow(img2); \n",
    "plt.show() \n",
    "\n",
    "plt.imshow(crop); \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
